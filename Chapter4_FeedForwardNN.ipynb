{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoOgMj51MV5q"
   },
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aACVeiQOMV5x"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): size of input dimension\n",
    "            hidden_dim (int): size of hidden dimension\n",
    "            output_dim (int): size of output dimension\n",
    "        \"\"\"\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_in (torch.Tensor): input data tensor with shape\n",
    "                (batch, input_dim)\n",
    "            apply_softmax (bool): flag for softmax activation\n",
    "                default false if using cross entropy\n",
    "        Returns:\n",
    "            resulting tensor with shape (batch, output_dim)\n",
    "        \"\"\"\n",
    "        intermediate = F.relu(self.fc1(x_in))\n",
    "        output = self.fc2(intermediate)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3amAxe4MV6J",
    "outputId": "583b51b6-d8f8-4802-fb4e-037cc3ee119f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_dim = 3\n",
    "output_dim = 4\n",
    "hidden_dim = 100\n",
    "\n",
    "# intialize model\n",
    "mlp = MultiLayerPerceptron(input_dim, hidden_dim, output_dim)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAoi-mIqMV6h",
    "outputId": "b9454ba1-7447-4ee5-a385-f097ef11560a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.0813, 0.6619, 0.3093],\n",
      "        [0.9877, 0.4410, 0.7280]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 4])\n",
      "Values: \n",
      "tensor([[ 0.0821, -0.2692, -0.2108,  0.1421],\n",
      "        [-0.0140, -0.1247, -0.2154,  0.2488]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# testing the MLP\n",
    "import torch\n",
    "\n",
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))\n",
    "\n",
    "\n",
    "# define input\n",
    "input_tensor = torch.rand(batch_size, input_dim)\n",
    "describe(input_tensor)\n",
    "\n",
    "# passing the input\n",
    "y_output = mlp(input_tensor, apply_softmax=False)\n",
    "describe(y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbBX07IcMV6x"
   },
   "source": [
    "The Rows in tensor are data point in mini batch\n",
    "The Columns are input features for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s98GTDC8MV6z",
    "outputId": "97c16ace-01e4-4840-b44f-5bef7b6feba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 4])\n",
      "Values: \n",
      "tensor([[0.2848, 0.2004, 0.2125, 0.3024],\n",
      "        [0.2492, 0.2231, 0.2037, 0.3241]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# producing probability output\n",
    "# with apply_softmax=True\n",
    "y_output = mlp(input_tensor, apply_softmax=True)\n",
    "describe(y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxu6SsCvMV7C"
   },
   "source": [
    "# MLP Surname Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5Co6h8NMV7E"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurnameDataset(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df_.iloc[index]\n",
    "        \n",
    "        surname_vector = self._vectorizer.vectorize(row.surname)\n",
    "        \n",
    "        nationality_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "        \n",
    "        return {\n",
    "            'x_surname': surname_vector,\n",
    "            'y_nationality': nationality_index\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvlFhLa_MV7S"
   },
   "source": [
    "# Surname Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03gbrTT3MmpG"
   },
   "source": [
    "## Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gUIjGGvDMV7V"
   },
   "outputs": [],
   "source": [
    "# create vocabulary class\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n",
    "    \n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        \n",
    "        self._idx_to_token = {\n",
    "            idx: token for token, idx in self._token_to_idx.items()\n",
    "        }\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "            \n",
    "    def to_serializeable(self):\n",
    "        \"\"\"return a serializeable dictionary\"\"\"\n",
    "        return {\n",
    "            'token_to_idx': self._token_to_idx,\n",
    "            'add_unk': self._add_unk,\n",
    "            'unk_token': self._unk_token\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializeable(cls, contents):\n",
    "        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n",
    "        return cls(**contents)\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Add a token and return it's index\"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"get the index of a token \n",
    "        if not exist returns the unk_index\"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "        \n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKwnEwufMV7i"
   },
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_pcOO4BwMV7j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "class SurnameVectorizer(object):\n",
    "    def __init__(self, surname_vocab, nationality_vocab):\n",
    "        self.surname_vocab = surname_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "        \n",
    "    def vectorize(self, surname):\n",
    "        \"\"\"Create one_hot vector for review\"\"\"\n",
    "        vocab = self.surname_vocab\n",
    "        one_hot = np.zeros(len(vocab), dtype=np.float32)\n",
    "        \n",
    "        for token in surname:\n",
    "          one_hot[vocab.lookup_token(token)] = 1\n",
    "                \n",
    "        return one_hot\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, dataframe, cutoff=25):\n",
    "        \"\"\"Instantiate a ReviewVector from dataset\"\"\"\n",
    "        \n",
    "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
    "        nationality_vocab = Vocabulary(add_unk=False)\n",
    "        \n",
    "        for index, row in dataframe.iterrows():\n",
    "            for letter in row.surname:\n",
    "                surname_vocab.add_token(letter)\n",
    "            nationality_vocab.add_token(row.nationality)\n",
    "            \n",
    "        return cls(surname_vocab, nationality_vocab)\n",
    "                \n",
    "        \n",
    "    @classmethod\n",
    "    def from_serializeable(cls, contents):\n",
    "        \"\"\"Instantiate vectorizer from serializeable\"\"\"\n",
    "        surname_vocab = Vocabulary.from_serializeable(contents['surname_vocab'])\n",
    "        nationality_vocab = Vocabulary.from_serializeable(contents['nationality_vocab'])\n",
    "        \n",
    "        return cls(surname_vocab, nationality_vocab)\n",
    "    \n",
    "    def to_serializeable(self):\n",
    "        return {\n",
    "            'surname_vocab': self.surname_vocab.to_serializeable(),\n",
    "            'nationality_vocab': self.nationality_vocab.to_serializeable()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGErbE6mMV7v"
   },
   "source": [
    "## Surname Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G9hgAvNEMV7x"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        self.surname_df = surname_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df = self.surname_df[self.surname_df.split == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.surname_df[self.surname_df.split == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.surname_df[self.surname_df.split == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                            'val': (self.val_df, self.val_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights to use with cross entropy\n",
    "        class_counts = surname_df.nationality.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, surname_csv, cuda=False):\n",
    "        \"\"\"Load dataset from csv and returns the dataset object\n",
    "        and vectorizer\"\"\"\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        train_surname_df = surname_df[surname_df.split == 'train']\n",
    "        return cls(surname_df,\n",
    "                   SurnameVectorizer.from_dataframe(train_surname_df))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\"Get vectorizer\"\"\"\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split='train'):\n",
    "        \"\"\"Set the split from data\"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        Args:\n",
    "            index (int): the index to the data point\n",
    "        Returns:\n",
    "            a dict of the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        surname_vector = self._vectorizer.vectorize(row.surname)\n",
    "        \n",
    "        nationality_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "        \n",
    "        return {\n",
    "            'x_data' : surname_vector,\n",
    "            'y_target' : nationality_index\n",
    "        }\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given the batch size return the number of batches in the dataset\"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G43KknW-MV79"
   },
   "source": [
    "## Surname Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V9gtbKIlMV7-"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SurnameClassifier(nn.Module):\n",
    "    \"\"\"2 layer multi perceptron multiclass classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"Forward pass the network given the x_in\"\"\"\n",
    "        \n",
    "        intermediate_vector = torch.relu(self.fc1(x_in))\n",
    "\n",
    "        # Adding dropout\n",
    "        # only applied in training\n",
    "        dropout = torch.nn.Dropout(p=.5)\n",
    "        if self.training:\n",
    "            prediction_vector = self.fc2(dropout(intermediate_vector))\n",
    "        else:\n",
    "            prediction_vector = self.fc2(intermediate_vector)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            prediction_vector = torch.softmax(prediction_vector, dim=1)\n",
    "        \n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC4dPjonMV8J"
   },
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AZKn-donMx4s",
    "outputId": "c30a02f3-6392-4d1a-9554-a4efe0738c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3xBzFE3rMV8L"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(\n",
    "    # Data information\n",
    "    frequency_cutoff = 25,\n",
    "    model_state_file = '/content/drive/My Drive/Colab Notebooks/Data/surname_dataset/model.pth',\n",
    "    surname_csv = '/content/drive/My Drive/Colab Notebooks/Data/surname_dataset/surnames_with_splits.csv',\n",
    "    save_dir = '/content/drive/My Drive/Colab Notebooks/Data/surname_dataset/',\n",
    "    vectorizer_file = '/content/drive/My Drive/Colab Notebooks/Data/surname_dataset/vectorizer.json',\n",
    "    # Model HyperParameters\n",
    "    hidden_dim = 500,\n",
    "    # Training HyperParameters\n",
    "    batch_size = 128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JJJrAbc9SLb9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will\n",
    "    ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "8SsHtsHCMV8X",
    "outputId": "85777c2e-50fb-44ff-dd9d-fc69fbcee4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available  cuda\n",
      "Input dim  77\n",
      "Output dim  18\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "# create variables to record\n",
    "# the training process\n",
    "def make_train_state(args):\n",
    "    return {\n",
    "        'epoch_index':0,\n",
    "        'train_loss':[],\n",
    "        'train_acc':[],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'test_loss': -1,\n",
    "        'test_acc': -1,\n",
    "    }\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "if torch.cuda.is_available() and args.cuda:\n",
    "  args.cuda = True\n",
    "else:\n",
    "  args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Device available \", args.device)\n",
    "\n",
    "# dataset object\n",
    "dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "\n",
    "# vectorizer\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# classifier\n",
    "classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab),\n",
    "                               hidden_dim=args.hidden_dim,\n",
    "                               output_dim = len(vectorizer.nationality_vocab))\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "\n",
    "print(\"Input dim \", len(vectorizer.surname_vocab))\n",
    "print(\"Output dim \", len(vectorizer.nationality_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "649693abb957474a8d3fbe6a7f9e327a",
      "501979e9f7644d1b9c32ab3cbd82189e",
      "dfa118bdb3dc4aa0811b7d38e31dc3ed",
      "b7719ee72f5f4708ae6f585e5cfe21a2",
      "25cb22009f2e4d93a470fa8ae852d685",
      "c9373075cff74c6db5d3d8a4efcbb58d",
      "5f81c4bef67a49b78f8d870b785db472",
      "aa479e7c0bb0464cbbbaf29db8765d21",
      "368b5717c61e41fbbc4fab00d9830462",
      "637ec9f1a4f64a00af591eed97200241",
      "a0f17843d31d4fe4bfe85ab78461fd44",
      "65338b539c1344688b59526715aa8fd0",
      "b2325e02f37d4210b48c968ba912c167",
      "5f66898174d54bc2b9507ad3e04d9c7e",
      "9bdeb7c5eae740de9b16748485cd11fa",
      "c443b0bbd9814040bed7ef70c3ffa36d",
      "2b1f91262f774ac585853386391223c4",
      "0b85d588ed9e434faa0706f01b4544e4",
      "3d860677ddba4fa0bcd159183fa800aa",
      "de8b0370da4e494dbd50984c77419545",
      "14fc5a86b4e94fc9b9cbd43b914990a4",
      "a7d6b90a3a7c4eb7909e93b9b7b4d989",
      "a9c2abe03779404abe37a674f80f7fb4",
      "0112f64328784ee4ab52e11db327ec81"
     ]
    },
    "id": "b3lYwfWwMV8j",
    "outputId": "7f31ad66-1265-4265-b134-9790f5976e24"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649693abb957474a8d3fbe6a7f9e327a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b5717c61e41fbbc4fab00d9830462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1f91262f774ac585853386391223c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=11.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training loop\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size)-1, \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size)-1, \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        # setup batch generator\n",
    "        # set loss and train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset=dataset,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        device=args.device)\n",
    "      \n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "      \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # step 1 zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "          \n",
    "            # step 2 compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'])\n",
    "          \n",
    "            # step 3 compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_batch = loss.item()\n",
    "            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "          \n",
    "            # step 4 use loss to produce gradients\n",
    "            loss.backward()\n",
    "          \n",
    "            # step 5 use optimizer to take the gradient step\n",
    "            optimizer.step()\n",
    "          \n",
    "            # step 6 compute the acccuracy\n",
    "            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "          \n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "      \n",
    "        # Iterate over val dataset\n",
    "        # setup: batch generator, set loss and acc to 0, set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        device=args.device)\n",
    "      \n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "      \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # step 1. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'])\n",
    "          \n",
    "            # step 2. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_batch = loss.item()\n",
    "            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "          \n",
    "            # step 3. compute the accuracy\n",
    "            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "            train_state['val_loss'].append(running_loss)\n",
    "            train_state['val_acc'].append(running_acc)\n",
    "            \n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "          \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "85pZBcghmRhD",
    "outputId": "2ca30907-a83c-40ea-f0fe-1430470ccb94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 2.059\n",
      "Test acc : 57.161\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset,\n",
    "                                   args.batch_size,\n",
    "                                   device=args.device)\n",
    "\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "  # compute the output\n",
    "  y_pred = classifier(x_in=batch_dict['x_data'])\n",
    "\n",
    "  # compute the loss\n",
    "  loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "  loss_batch = loss.item()\n",
    "  running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "\n",
    "  # compute the accuracy\n",
    "  acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "  running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc\n",
    "\n",
    "print(\"Test loss : {:.3f}\".format(train_state['test_loss']))\n",
    "print(\"Test acc : {:.3f}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "4wBfhcbDlwXy",
    "outputId": "768574be-36f3-4022-ba19-50a5b61e320e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a surname to classify: wong\n",
      "wong -> Chinese (p=0.69)\n"
     ]
    }
   ],
   "source": [
    "# Inference mode\n",
    "\n",
    "def predict_nationality(surname, classifier, vectorizer):\n",
    "    \"\"\"Predict the nationality from a new surname\n",
    "    \n",
    "    Args:\n",
    "        surname (str): the surname to classifier\n",
    "        classifier (SurnameClassifer): an instance of the classifier\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        a dictionary with the most likely nationality and its probability\n",
    "    \"\"\"\n",
    "    vectorized_surname = vectorizer.vectorize(surname)\n",
    "    vectorized_surname = torch.tensor(vectorized_surname).view(1, -1)\n",
    "    result = classifier(vectorized_surname, apply_softmax=True)\n",
    "\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    index = indices.item()\n",
    "\n",
    "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return {'nationality': predicted_nationality, 'probability': probability_value}\n",
    "\n",
    "new_surname = input(\"Enter a surname to classify: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "prediction = predict_nationality(new_surname, classifier, vectorizer)\n",
    "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                    prediction['nationality'],\n",
    "                                    prediction['probability']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Chapter4_FeedForwardNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0112f64328784ee4ab52e11db327ec81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b85d588ed9e434faa0706f01b4544e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14fc5a86b4e94fc9b9cbd43b914990a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "25cb22009f2e4d93a470fa8ae852d685": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2b1f91262f774ac585853386391223c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d860677ddba4fa0bcd159183fa800aa",
       "IPY_MODEL_de8b0370da4e494dbd50984c77419545"
      ],
      "layout": "IPY_MODEL_0b85d588ed9e434faa0706f01b4544e4"
     }
    },
    "368b5717c61e41fbbc4fab00d9830462": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0f17843d31d4fe4bfe85ab78461fd44",
       "IPY_MODEL_65338b539c1344688b59526715aa8fd0"
      ],
      "layout": "IPY_MODEL_637ec9f1a4f64a00af591eed97200241"
     }
    },
    "3d860677ddba4fa0bcd159183fa800aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "split=val: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d6b90a3a7c4eb7909e93b9b7b4d989",
      "max": 11,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14fc5a86b4e94fc9b9cbd43b914990a4",
      "value": 11
     }
    },
    "501979e9f7644d1b9c32ab3cbd82189e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f66898174d54bc2b9507ad3e04d9c7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f81c4bef67a49b78f8d870b785db472": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "637ec9f1a4f64a00af591eed97200241": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649693abb957474a8d3fbe6a7f9e327a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfa118bdb3dc4aa0811b7d38e31dc3ed",
       "IPY_MODEL_b7719ee72f5f4708ae6f585e5cfe21a2"
      ],
      "layout": "IPY_MODEL_501979e9f7644d1b9c32ab3cbd82189e"
     }
    },
    "65338b539c1344688b59526715aa8fd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c443b0bbd9814040bed7ef70c3ffa36d",
      "placeholder": "​",
      "style": "IPY_MODEL_9bdeb7c5eae740de9b16748485cd11fa",
      "value": " 59/59 [03:28&lt;00:00,  5.73s/it, acc=62.3, epoch=99, loss=0.752]"
     }
    },
    "9bdeb7c5eae740de9b16748485cd11fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0f17843d31d4fe4bfe85ab78461fd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "split=train: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f66898174d54bc2b9507ad3e04d9c7e",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2325e02f37d4210b48c968ba912c167",
      "value": 59
     }
    },
    "a7d6b90a3a7c4eb7909e93b9b7b4d989": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9c2abe03779404abe37a674f80f7fb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa479e7c0bb0464cbbbaf29db8765d21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2325e02f37d4210b48c968ba912c167": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b7719ee72f5f4708ae6f585e5cfe21a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa479e7c0bb0464cbbbaf29db8765d21",
      "placeholder": "​",
      "style": "IPY_MODEL_5f81c4bef67a49b78f8d870b785db472",
      "value": " 100/100 [03:28&lt;00:00,  2.05s/it]"
     }
    },
    "c443b0bbd9814040bed7ef70c3ffa36d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9373075cff74c6db5d3d8a4efcbb58d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de8b0370da4e494dbd50984c77419545": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0112f64328784ee4ab52e11db327ec81",
      "placeholder": "​",
      "style": "IPY_MODEL_a9c2abe03779404abe37a674f80f7fb4",
      "value": " 11/11 [03:28&lt;00:00,  5.79s/it, acc=55.7, epoch=99, loss=2.03]"
     }
    },
    "dfa118bdb3dc4aa0811b7d38e31dc3ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "training routine: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9373075cff74c6db5d3d8a4efcbb58d",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25cb22009f2e4d93a470fa8ae852d685",
      "value": 100
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

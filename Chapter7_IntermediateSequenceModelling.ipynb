{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Chapter6_IntermediateSequenceModelling.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cfbf3e85f8b54b58b47ceb7043cbd75a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a88569dc586d419cb12e7a321ea69f08","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95f387ab0d3c4efc89b90eb0dd4a052c","IPY_MODEL_0c9b59fef4234470bb759e0beeb5f357"]}},"a88569dc586d419cb12e7a321ea69f08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95f387ab0d3c4efc89b90eb0dd4a052c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_596fffa5d99d41b59ee1505034d25d67","_dom_classes":[],"description":"training routine: 100%","_model_name":"FloatProgressModel","bar_style":"","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88f19aea90544897bcc5279675ab4d84"}},"0c9b59fef4234470bb759e0beeb5f357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40c5aa24576c4b718c3ba94c91388c75","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100/100 [04:05&lt;00:00,  2.42s/it, sample1=Kake, sample2=Baochine]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9cd230d0a9aa4bdd95ec1fde2b691312"}},"596fffa5d99d41b59ee1505034d25d67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88f19aea90544897bcc5279675ab4d84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40c5aa24576c4b718c3ba94c91388c75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9cd230d0a9aa4bdd95ec1fde2b691312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6430e6c050c541b98cc7e593514c0aeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2509dd9d8f464ee8bbe6bd8c09eabeda","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_192253906b7e4f9c80231e117e414e05","IPY_MODEL_0a633dbd4f8b4b018c501e35283fe4a3"]}},"2509dd9d8f464ee8bbe6bd8c09eabeda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"192253906b7e4f9c80231e117e414e05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ee94dd1b1124ff7a21cc73b6139bdef","_dom_classes":[],"description":"split=train: 100%","_model_name":"FloatProgressModel","bar_style":"","max":59,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":59,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e0bfb650d2b452dbd1858619d17a23d"}},"0a633dbd4f8b4b018c501e35283fe4a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_939a6a56c7394ca58b975a80f0ed8dd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 59/59 [04:05&lt;00:00,  5.38s/it, acc=33.2, epoch=99, loss=2.24]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e30ffd42ef6c40f2aa049ed8c5a0e59d"}},"4ee94dd1b1124ff7a21cc73b6139bdef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e0bfb650d2b452dbd1858619d17a23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"939a6a56c7394ca58b975a80f0ed8dd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e30ffd42ef6c40f2aa049ed8c5a0e59d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41cfc90eae614b408360b2df97d5683f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c980aa87fa084310a599a54352ce43ac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a337e3c3fa7d4c9f8b0af0d8a816bfad","IPY_MODEL_1d094c2bdb46476d8cb9275b6835756c"]}},"c980aa87fa084310a599a54352ce43ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a337e3c3fa7d4c9f8b0af0d8a816bfad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d6cf7b0e403496fb0150fdcc65d60e9","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":11,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":11,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db135241c23748ee8b0de42282f3fa75"}},"1d094c2bdb46476d8cb9275b6835756c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32cd9c43c01647569e63dca8f8887d32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 11/11 [04:05&lt;00:00,  5.46s/it, acc=33.5, epoch=99, loss=2.24]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb136c530c054f498df66d1f8797af7c"}},"9d6cf7b0e403496fb0150fdcc65d60e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"db135241c23748ee8b0de42282f3fa75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32cd9c43c01647569e63dca8f8887d32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cb136c530c054f498df66d1f8797af7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"248ca61c115043d298f8bf2b63f2824b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2027b822b5b24a238873433857c81d17","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2649f4d3ff4428381c50ee7457ff54e","IPY_MODEL_d539be6c6bc54922a553177815cd9a4c"]}},"2027b822b5b24a238873433857c81d17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2649f4d3ff4428381c50ee7457ff54e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62e36471886a45d4abf3c140ce63f53a","_dom_classes":[],"description":"training routine: 100%","_model_name":"FloatProgressModel","bar_style":"","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60460b670784487f95e7f68320205c05"}},"d539be6c6bc54922a553177815cd9a4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc09a5e529b346e7996dfd5090163b6c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100/100 [04:03&lt;00:00,  2.45s/it, sample1=Genball, sample2=Lugars]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0da435e39734c94b8cafacef5bd0123"}},"62e36471886a45d4abf3c140ce63f53a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"60460b670784487f95e7f68320205c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc09a5e529b346e7996dfd5090163b6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0da435e39734c94b8cafacef5bd0123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf9c0f5717854e5fa67c1b58921a7f53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4d53b0c7c6d9479b89d97b09589f2cf5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1a9b10df8ae34f689cf6b230573cc25c","IPY_MODEL_ad0b7c58593a49f7be96fbaed33149e1"]}},"4d53b0c7c6d9479b89d97b09589f2cf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a9b10df8ae34f689cf6b230573cc25c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d92d5cfe9cc74a99aa122323210dad0c","_dom_classes":[],"description":"split=train: 100%","_model_name":"FloatProgressModel","bar_style":"","max":59,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":59,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acf5001d378d4fd6b76c1c97d89a60f1"}},"ad0b7c58593a49f7be96fbaed33149e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f45d07beb35e4fc8813ee01b37481d0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 59/59 [04:02&lt;00:00,  4.86s/it, acc=38, epoch=99, loss=2.05]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f30711aa2c34d8f9ec61e62a6551abf"}},"d92d5cfe9cc74a99aa122323210dad0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acf5001d378d4fd6b76c1c97d89a60f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f45d07beb35e4fc8813ee01b37481d0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f30711aa2c34d8f9ec61e62a6551abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"465d9f7c961e43e3967d6f8db646c3a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8c20e9fd3e1644c0909f07cbc28cd6aa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a40564bd1d894770a2330343bb2e78ab","IPY_MODEL_bb296ed0ebe34279b2a78b8039c6b649"]}},"8c20e9fd3e1644c0909f07cbc28cd6aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a40564bd1d894770a2330343bb2e78ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_565ead1fbe3a47d9b5632c02b0399763","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":11,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":11,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0054db0dcd9429ba51f23b963d0bef9"}},"bb296ed0ebe34279b2a78b8039c6b649":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ac2c54ea135943439680c57de791abca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 11/11 [04:03&lt;00:00,  5.94s/it, acc=38.8, epoch=99, loss=2.04]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60fc6c3a0f934c0a90073a132d5fcacc"}},"565ead1fbe3a47d9b5632c02b0399763":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a0054db0dcd9429ba51f23b963d0bef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac2c54ea135943439680c57de791abca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60fc6c3a0f934c0a90073a132d5fcacc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"v9GeR4y96Hc5"},"source":["# Surname Generation using RNN"]},{"cell_type":"code","metadata":{"id":"8BjmBgBl6XXL","executionInfo":{"status":"ok","timestamp":1604216758301,"user_tz":-420,"elapsed":59882,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"662f14c9-a8d7-41ee-a5e6-4df1e99298fa","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CIMHMeS6Hc_","executionInfo":{"status":"ok","timestamp":1604216769308,"user_tz":-420,"elapsed":6319,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["import numpy as np\n","from collections import Counter\n","import string\n","import torch\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from argparse import Namespace\n","import torch.optim as optim\n","from tqdm.notebook import tqdm\n","import torch.nn.functional as F\n","import re"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVbx8ivR6HdY"},"source":["## Sequence Vocabulary"]},{"cell_type":"code","metadata":{"id":"tWZg5IGF6Hdg","executionInfo":{"status":"ok","timestamp":1604216769311,"user_tz":-420,"elapsed":3790,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class SequenceVocabulary(object):\n","    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n","    \n","    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n","        if token_to_idx is None:\n","            token_to_idx = {}\n","        self._token_to_idx = token_to_idx\n","        \n","        self._idx_to_token = {\n","            idx: token for token, idx in self._token_to_idx.items()\n","        }\n","        \n","        self._add_unk = add_unk\n","        self._unk_token = unk_token\n","        self._mask_token = mask_token\n","        \n","        # add begin and end sequence token\n","        self._begin_of_seq_token = \"<BEGIN-OF-SEQUENCE>\"\n","        self._end_of_seq_token = \"<END-OF-SEQUENCE>\"\n","        \n","        self.begin_seq_index = self.add_token(self._begin_of_seq_token)\n","        self.end_seq_index = self.add_token(self._end_of_seq_token)\n","\n","        self.mask_index = self.add_token(mask_token)\n","        self.unk_index = -1\n","        if add_unk:\n","            self.unk_index = self.add_token(unk_token)\n","            \n","    def to_serializeable(self):\n","        \"\"\"return a serializeable dictionary\"\"\"\n","        return {\n","            'token_to_idx': self._token_to_idx,\n","            'mask_token': self._mask_token,\n","            'add_unk': self._add_unk,\n","            'unk_token': self._unk_token\n","        }\n","    \n","    @classmethod\n","    def from_serializeable(cls, contents):\n","        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n","        return cls(**contents)\n","    \n","    def add_token(self, token):\n","        \"\"\"Add a token and return it's index\"\"\"\n","        if token in self._token_to_idx:\n","            index = self._token_to_idx[token]\n","        else:\n","            index = len(self._token_to_idx)\n","            self._token_to_idx[token] = index\n","            self._idx_to_token[index] = token\n","        return index\n","    \n","    def lookup_token(self, token):\n","        \"\"\"get the index of a token \n","        if not exist returns the unk_index\"\"\"\n","        if self.unk_index >= 0:\n","            return self._token_to_idx.get(token, self.unk_index)\n","        else:\n","            return self._token_to_idx[token]\n","        \n","    def lookup_index(self, index):\n","        if index not in self._idx_to_token:\n","            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n","        return self._idx_to_token[index]\n","    \n","    def __str__(self):\n","        return \"<Vocabulary(size=%d)>\" % len(self)\n","    \n","    def __len__(self):\n","        return len(self._token_to_idx)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivSUU3Kx6Hdv","executionInfo":{"status":"ok","timestamp":1604216772296,"user_tz":-420,"elapsed":1794,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["# create vocabulary class\n","class Vocabulary(object):\n","    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n","    \n","    def __init__(self, token_to_idx=None):\n","        if token_to_idx is None:\n","            token_to_idx = {}\n","        self._token_to_idx = token_to_idx\n","        \n","        self._idx_to_token = {\n","            idx: token for token, idx in self._token_to_idx.items()\n","        }\n","\n","    def to_serializeable(self):\n","        \"\"\"return a serializeable dictionary\"\"\"\n","        return {\n","            'token_to_idx': self._token_to_idx\n","        }\n","    \n","    @classmethod\n","    def from_serializeable(cls, contents):\n","        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n","        return cls(**contents)\n","    \n","    def add_token(self, token):\n","        \"\"\"Add a token and return it's index\"\"\"\n","        if token in self._token_to_idx:\n","            index = self._token_to_idx[token]\n","        else:\n","            index = len(self._token_to_idx)\n","            self._token_to_idx[token] = index\n","            self._idx_to_token[index] = token\n","        return index\n","    \n","    def lookup_token(self, token):\n","        \"\"\"get the index of a token \n","        if not exist returns the unk_index\"\"\"\n","        return self._token_to_idx[token]\n","        \n","    def lookup_index(self, index):\n","        if index not in self._idx_to_token:\n","            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n","        return self._idx_to_token[index]\n","    \n","    def __str__(self):\n","        return \"<Vocabulary(size=%d)>\" % len(self)\n","    \n","    def __len__(self):\n","        return len(self._token_to_idx)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fEXdtchk6Hd_"},"source":["## Vectorizer"]},{"cell_type":"code","metadata":{"id":"MLIiH3SL6HeB","executionInfo":{"status":"ok","timestamp":1604216774415,"user_tz":-420,"elapsed":1540,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class SurnameVectorizer(object):\n","    def __init__(self, char_vocab, nationality_vocab):\n","        self.char_vocab = char_vocab\n","        self.nationality_vocab = nationality_vocab\n","    \n","    def vectorize(self, surname, vector_length=-1):\n","        indices = [self.char_vocab.begin_seq_index]\n","        indices.extend(self.char_vocab.lookup_token(token)\n","                    for token in surname)\n","        indices.append(self.char_vocab.end_seq_index)\n","\n","        if vector_length < 0:\n","            vector_length = len(indices) - 1\n","\n","        from_vector = np.zeros(vector_length, dtype=np.int64)\n","        from_indices = indices[:-1]\n","        from_vector[:len(from_indices)] = from_indices\n","        from_vector[len(from_indices)] = self.char_vocab.mask_index\n","\n","        to_vector = np.empty(vector_length, dtype=np.int64)\n","        to_indices = indices[1:]\n","        to_vector[:len(to_indices)] = to_indices\n","        to_vector[len(to_indices):] = self.char_vocab.mask_index\n","\n","        return from_vector, to_vector\n","    \n","    @classmethod\n","    def from_dataframe(cls, surname_df, cutoff=25):\n","        nationality_vocab = Vocabulary()\n","        character_vocab = SequenceVocabulary()\n","        \n","        for index, row in surname_df.iterrows():\n","            for char in row.surname:\n","                character_vocab.add_token(char)\n","            nationality_vocab.add_token(row.nationality)\n","        \n","        return cls(character_vocab, nationality_vocab)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jt6YvWJa6HeO"},"source":["## Surname Dataset"]},{"cell_type":"code","metadata":{"id":"0xC91vvL6HeS","executionInfo":{"status":"ok","timestamp":1604216777099,"user_tz":-420,"elapsed":2463,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torch\n","\n","class SurnameDataset(Dataset):\n","    def __init__(self, surname_df, vectorizer):\n","        self.surname_df = surname_df\n","        self._vectorizer = vectorizer\n","\n","        self._max_seq_length = max(map(len, self.surname_df.surname)) + 2\n","        \n","        self.train_df = self.surname_df[self.surname_df.split == 'train']\n","        self.train_size = len(self.train_df)\n","        \n","        self.val_df = self.surname_df[self.surname_df.split == 'val']\n","        self.val_size = len(self.val_df)\n","        \n","        self.test_df = self.surname_df[self.surname_df.split == 'test']\n","        self.test_size = len(self.test_df)\n","        \n","        self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                            'val': (self.val_df, self.val_size),\n","                            'test': (self.test_df, self.test_size)}\n","        \n","        self.set_split('train')\n","\n","        # Class weights to use with cross entropy\n","        class_counts = surname_df.nationality.value_counts().to_dict()\n","        def sort_key(item):\n","            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n","        sorted_counts = sorted(class_counts.items(), key=sort_key)\n","        frequencies = [count for _, count in sorted_counts]\n","        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n","        \n","    @classmethod\n","    def load_dataset_and_make_vectorizer(cls, surname_csv, cuda=False):\n","        \"\"\"Load dataset from csv and returns the dataset object\n","        and vectorizer\"\"\"\n","        surname_df = pd.read_csv(surname_csv)\n","        train_surname_df = surname_df[surname_df.split == 'train']\n","        return cls(surname_df,\n","                   SurnameVectorizer.from_dataframe(train_surname_df))\n","    \n","    def get_vectorizer(self):\n","        \"\"\"Get vectorizer\"\"\"\n","        return self._vectorizer\n","    \n","    def set_split(self, split='train'):\n","        \"\"\"Set the split from data\"\"\"\n","        self._target_split = split\n","        self._target_df, self._target_size = self._lookup_dict[split]\n","        \n","    def __len__(self):\n","        return self._target_size\n","    \n","    def __getitem__(self, index):\n","        \"\"\"the primary entry point method for PyTorch datasets\n","        Args:\n","            index (int): the index to the data point\n","        Returns:\n","            a dict of the data point's features (x_data) and label (y_target)\n","        \"\"\"\n","        row = self._target_df.iloc[index]\n","        \n","        surname_vector, vec_length = self._vectorizer.vectorize(row.surname,\n","                                                               self._max_seq_length)\n","        \n","        nationality_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n","        \n","        return {\n","            'x_data' : surname_vector,\n","            'class_index' : nationality_index,\n","            'y_target': vec_length\n","        }\n","    \n","    def get_num_batches(self, batch_size):\n","        \"\"\"Given the batch size return the number of batches in the dataset\"\"\"\n","        return len(self) // batch_size"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWqCTUSb6Hei"},"source":["## Unconditioned Model"]},{"cell_type":"code","metadata":{"id":"ElLZSLhz6Hek","executionInfo":{"status":"ok","timestamp":1604216778440,"user_tz":-420,"elapsed":981,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class SurnameGenerationModel(nn.Module):\n","    def __init__(self, char_embedding_size, char_vocab_size,\n","                rnn_hidden_size, batch_first=True, padding_idx=0,\n","                dropout_p=.5):\n","        super(SurnameGenerationModel, self).__init__()\n","        \n","        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n","                                    embedding_dim=char_embedding_size,\n","                                    padding_idx=padding_idx)\n","        self.rnn = nn.GRU(input_size= char_embedding_size,\n","                         hidden_size= rnn_hidden_size,\n","                         batch_first= batch_first)\n","        self.fc = nn.Linear(in_features= rnn_hidden_size,\n","                           out_features= char_vocab_size)\n","        self.dropout = torch.nn.Dropout(p= dropout_p)\n","        \n","    def forward(self, x_in, apply_softmax=False):\n","        x_embedded = self.char_emb(x_in)\n","        \n","        y_out,_ = self.rnn(x_embedded)\n","        batch_size, seq_size, feat_size = y_out.shape\n","        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n","        \n","        y_out = self.fc(self.dropout(y_out))\n","        \n","        if apply_softmax:\n","            y_out = torch.Softmax(y_out, dim=1)\n","            \n","        new_feat_size = y_out.shape[-1]\n","        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n","        \n","        return y_out"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnxOwUaj0KOf"},"source":["## Conditined Model"]},{"cell_type":"code","metadata":{"id":"EPTquatV0P1B","executionInfo":{"status":"ok","timestamp":1604218705466,"user_tz":-420,"elapsed":853,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class SurnameGenerationModelConditioned(nn.Module):\n","    def __init__(self, char_embedding_size,num_nationalities, char_vocab_size,\n","                rnn_hidden_size, batch_first=True, padding_idx=0,\n","                dropout_p=.5):\n","        super(SurnameGenerationModelConditioned, self).__init__()\n","        \n","        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n","                                    embedding_dim=char_embedding_size,\n","                                    padding_idx=padding_idx)\n","        self.rnn = nn.GRU(input_size= char_embedding_size,\n","                         hidden_size= rnn_hidden_size,\n","                         batch_first= batch_first)\n","        self.fc = nn.Linear(in_features= rnn_hidden_size,\n","                           out_features= char_vocab_size)\n","        self.dropout = torch.nn.Dropout(p= dropout_p)\n","\n","        # adding nation embedding\n","        # to add bias into the model\n","        self.nation_embedding = nn.Embedding(num_embeddings= num_nationalities,\n","                                             embedding_dim= rnn_hidden_size)\n","        \n","    def forward(self, x_in, nationality_index, apply_softmax=False):\n","        x_embedded = self.char_emb(x_in)\n","        \n","        # add nationality embedding\n","        nationality_embedding = self.nation_embedding(nationality_index).unsqueeze(0)\n","        # adding initial hidden layers weight\n","        y_out,_ = self.rnn(x_embedded, nationality_embedding)\n","        \n","        batch_size, seq_size, feat_size = y_out.shape\n","        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n","        \n","        y_out = self.fc(self.dropout(y_out))\n","        \n","        if apply_softmax:\n","            y_out = torch.Softmax(y_out, dim=1)\n","            \n","        new_feat_size = y_out.shape[-1]\n","        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n","        \n","        return y_out"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Njy-G8iP6Hew"},"source":["## Helper Function"]},{"cell_type":"code","metadata":{"id":"ECX4wXB46Hey","executionInfo":{"status":"ok","timestamp":1604216782545,"user_tz":-420,"elapsed":1240,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["def normalize_sizes(y_pred, y_true):\n","    \"\"\"Normalize tensor sizes\n","    \n","    Args:\n","        y_pred (torch.Tensor): the output of the model\n","            If a 3-dimensional tensor, reshapes to a matrix\n","        y_true (torch.Tensor): the target predictions\n","            If a matrix, reshapes to be a vector\n","    \"\"\"\n","    if len(y_pred.size()) == 3:\n","        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n","    if len(y_true.size()) == 2:\n","        y_true = y_true.contiguous().view(-1)\n","    return y_pred, y_true\n","\n","# compute the model loss\n","def sequence_loss(y_pred, y_true, mask_index):\n","    y_pred, y_true = normalize_sizes(y_pred, y_true)\n","    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\n","\n","def compute_accuracy(y_pred, y_true, mask_index):\n","    y_pred, y_true = normalize_sizes(y_pred, y_true)\n","\n","    _, y_pred_indices = y_pred.max(dim=1)\n","    \n","    correct_indices = torch.eq(y_pred_indices, y_true).float()\n","    valid_indices = torch.ne(y_true, mask_index).float()\n","    \n","    n_correct = (correct_indices * valid_indices).sum().item()\n","    n_valid = valid_indices.sum().item()\n","\n","    return n_correct / n_valid * 100"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEJJQO_9uoox","executionInfo":{"status":"ok","timestamp":1604216785360,"user_tz":-420,"elapsed":1049,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \n","                      temperature=1.0):\n","    \"\"\"Sample a sequence of indices from the model\n","    \n","    Args:\n","        model (SurnameGenerationModel): the trained model\n","        vectorizer (SurnameVectorizer): the corresponding vectorizer\n","        num_samples (int): the number of samples\n","        sample_size (int): the max length of the samples\n","        temperature (float): accentuates or flattens \n","            the distribution. \n","            0.0 < temperature < 1.0 will make it peakier. \n","            temperature > 1.0 will make it more uniform\n","    Returns:\n","        indices (torch.Tensor): the matrix of indices; \n","        shape = (num_samples, sample_size)\n","    \"\"\"\n","    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n","                       for _ in range(num_samples)]\n","    begin_seq_index = torch.tensor(begin_seq_index, \n","                                   dtype=torch.int64).unsqueeze(dim=1)\n","    indices = [begin_seq_index]\n","    h_t = None\n","    \n","    for time_step in range(sample_size):\n","        x_t = indices[time_step]\n","        x_emb_t = model.char_emb(x_t)\n","        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n","        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n","        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n","        indices.append(torch.multinomial(probability_vector, num_samples=1))\n","    indices = torch.stack(indices).squeeze().permute(1, 0)\n","    return indices\n","\n","def decode_samples(sampled_indices, vectorizer):\n","    \"\"\"Transform indices into the string form of a surname\n","    \n","    Args:\n","        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\n","        vectorizer (SurnameVectorizer): the corresponding vectorizer\n","    \"\"\"\n","    decoded_surnames = []\n","    vocab = vectorizer.char_vocab\n","    \n","    for sample_index in range(sampled_indices.shape[0]):\n","        surname = \"\"\n","        for time_step in range(sampled_indices.shape[1]):\n","            sample_item = sampled_indices[sample_index, time_step].item()\n","            if sample_item == vocab.begin_seq_index:\n","                continue\n","            elif sample_item == vocab.end_seq_index:\n","                break\n","            else:\n","                surname += vocab.lookup_index(sample_item)\n","        decoded_surnames.append(surname)\n","    return decoded_surnames"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fh8TXdsi6He6"},"source":["## Unconditioned Model Training Routine\n"]},{"cell_type":"code","metadata":{"id":"GxlFLykK6He8"},"source":["args = Namespace(\n","    # Data information\n","    frequency_cutoff = 25,\n","    model_state_file = '/content/drive/My Drive/Colab Notebooks/Data/model.pth',\n","    surname_csv = '/content/drive/My Drive/Colab Notebooks/Data/surnames_with_splits.csv',\n","    save_dir = '/content/drive/My Drive/Colab Notebooks/Data',\n","    vectorizer_file = '/content/drive/My Drive/Colab Notebooks/Data/vectorizer.json',\n","    # Model HyperParameters\n","    char_embedding_size = 100,\n","    rnn_hidden_size=64,\n","    # Training HyperParameters\n","    batch_size = 128,\n","    early_stopping_criteria=5,\n","    learning_rate=0.001,\n","    momentum=0.1,\n","    num_epochs=100,\n","    seed=1337,\n","    cuda=True,\n","    dropout=0.1\n",")\n","\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"):\n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will\n","    ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last)\n","\n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        for name, tensor in data_dict.items():\n","            out_data_dict[name] = data_dict[name].to(device)\n","        yield out_data_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Hbr1Eun6HfH","executionInfo":{"status":"ok","timestamp":1604216811065,"user_tz":-420,"elapsed":14068,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"33ea6cee-3597-4c61-822c-ddb82d7f60fb","colab":{"base_uri":"https://localhost:8080/"}},"source":["# create variables to record\n","# the training process\n","def make_train_state(args):\n","    return {\n","        'epoch_index':0,\n","        'train_loss':[],\n","        'train_acc':[],\n","        'val_loss': [],\n","        'val_acc': [],\n","        'test_loss': -1,\n","        'test_acc': -1,\n","    }\n","\n","train_state = make_train_state(args)\n","\n","if torch.cuda.is_available() and args.cuda:\n","  args.cuda = True\n","else:\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Device available \", args.device)\n","\n","# dataset object\n","dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n","\n","# vectorizer\n","vectorizer = dataset.get_vectorizer()\n","\n","# classifier\n","\n","vectorizer = dataset.get_vectorizer()\n","\n","conditionedModel = SurnameGenerationModel(char_embedding_size=args.char_embedding_size,\n","                               char_vocab_size=len(vectorizer.char_vocab),\n","                               rnn_hidden_size=args.rnn_hidden_size,\n","                               padding_idx=vectorizer.char_vocab.mask_index)\n","model.to(args.device)\n","\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Device available  cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FVucurvK6HfR","executionInfo":{"status":"ok","timestamp":1604217065637,"user_tz":-420,"elapsed":246991,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"c6701991-09b4-44db-bf60-d63a466f12c8","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cfbf3e85f8b54b58b47ceb7043cbd75a","a88569dc586d419cb12e7a321ea69f08","95f387ab0d3c4efc89b90eb0dd4a052c","0c9b59fef4234470bb759e0beeb5f357","596fffa5d99d41b59ee1505034d25d67","88f19aea90544897bcc5279675ab4d84","40c5aa24576c4b718c3ba94c91388c75","9cd230d0a9aa4bdd95ec1fde2b691312","6430e6c050c541b98cc7e593514c0aeb","2509dd9d8f464ee8bbe6bd8c09eabeda","192253906b7e4f9c80231e117e414e05","0a633dbd4f8b4b018c501e35283fe4a3","4ee94dd1b1124ff7a21cc73b6139bdef","1e0bfb650d2b452dbd1858619d17a23d","939a6a56c7394ca58b975a80f0ed8dd2","e30ffd42ef6c40f2aa049ed8c5a0e59d","41cfc90eae614b408360b2df97d5683f","c980aa87fa084310a599a54352ce43ac","a337e3c3fa7d4c9f8b0af0d8a816bfad","1d094c2bdb46476d8cb9275b6835756c","9d6cf7b0e403496fb0150fdcc65d60e9","db135241c23748ee8b0de42282f3fa75","32cd9c43c01647569e63dca8f8887d32","cb136c530c054f498df66d1f8797af7c"]}},"source":["mask_index = vectorizer.char_vocab.mask_index\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size)-1, \n","                          position=1, \n","                          leave=True)\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size)-1, \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","    for epoch_index in range(args.num_epochs):\n","        train_state['epoch_index'] = epoch_index\n","\n","        # Iterate over training dataset\n","\n","        # setup: batch generator, set loss and acc to 0, set train mode on\n","        dataset.set_split('train')\n","        batch_generator = generate_batches(dataset, \n","                                           batch_size=args.batch_size, \n","                                           device=args.device)\n","        running_loss = 0.0\n","        running_acc = 0.0\n","        model.train()\n","        \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # the training routine is these 5 steps:\n","\n","            # --------------------------------------    \n","            # step 1. zero the gradients\n","            optimizer.zero_grad()\n","\n","            # step 2. compute the output\n","            y_pred = model(x_in=batch_dict['x_data'])\n","\n","            # step 3. compute the loss\n","            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","\n","            # step 4. use loss to produce gradients\n","            loss.backward()\n","\n","            # step 5. use optimizer to take gradient step\n","            optimizer.step()\n","            # -----------------------------------------\n","            # compute the  running loss and running accuracy\n","            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","            running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","            # update bar\n","            train_bar.set_postfix(loss=running_loss,\n","                                  acc=running_acc,\n","                                  epoch=epoch_index)\n","            train_bar.update()\n","\n","        train_state['train_loss'].append(running_loss)\n","        train_state['train_acc'].append(running_acc)\n","\n","        # Iterate over val dataset\n","\n","        # setup: batch generator, set loss and acc to 0; set eval mode on\n","        dataset.set_split('val')\n","        batch_generator = generate_batches(dataset, \n","                                           batch_size=args.batch_size, \n","                                           device=args.device)\n","        running_loss = 0.\n","        running_acc = 0.\n","        model.eval()\n","\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # compute the output\n","            y_pred = model(x_in=batch_dict['x_data'])\n","\n","            # step 3. compute the loss\n","            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","            # compute the  running loss and running accuracy\n","            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","            running_acc += (acc_t - running_acc) / (batch_index + 1)\n","            \n","            # Update bar\n","            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                            epoch=epoch_index)\n","            val_bar.update()\n","\n","        train_state['val_loss'].append(running_loss)\n","        train_state['val_acc'].append(running_acc)\n","        \n","        # move model to cpu for sampling\n","        model = model.cpu()\n","        sampled_surnames = decode_samples(\n","            sample_from_model(model, vectorizer, num_samples=2), \n","            vectorizer)\n","        epoch_bar.set_postfix(sample1=sampled_surnames[0], \n","                              sample2=sampled_surnames[1])\n","        # move model back to whichever device it should be on\n","        model = model.to(args.device)\n","        \n","        train_bar.n = 0\n","        val_bar.n = 0\n","        epoch_bar.update()\n","        \n","except KeyboardInterrupt:\n","    print(\"Exiting loop\")"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfbf3e85f8b54b58b47ceb7043cbd75a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6430e6c050c541b98cc7e593514c0aeb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41cfc90eae614b408360b2df97d5683f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=11.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Tpla0bea3dkd"},"source":["## Conditioned Model Training Routine"]},{"cell_type":"code","metadata":{"id":"N8UoZMj53h6d","executionInfo":{"status":"ok","timestamp":1604219076410,"user_tz":-420,"elapsed":2113,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"301c1525-a421-484e-a5cd-b76d1b1170dc","colab":{"base_uri":"https://localhost:8080/"}},"source":["def make_train_state(args):\n","    return {\n","        'epoch_index':0,\n","        'train_loss':[],\n","        'train_acc':[],\n","        'val_loss': [],\n","        'val_acc': [],\n","        'test_loss': -1,\n","        'test_acc': -1,\n","    }\n","\n","train_state = make_train_state(args)\n","\n","if torch.cuda.is_available() and args.cuda:\n","  args.cuda = True\n","else:\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Device available \", args.device)\n","\n","# dataset object\n","dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n","\n","# vectorizer\n","vectorizer = dataset.get_vectorizer()\n","\n","# model\n","modelConditioned = SurnameGenerationModelConditioned(char_embedding_size=args.char_embedding_size,\n","                               char_vocab_size=len(vectorizer.char_vocab),\n","                               num_nationalities=len(vectorizer.nationality_vocab),\n","                               rnn_hidden_size=args.rnn_hidden_size,\n","                               padding_idx=vectorizer.char_vocab.mask_index,\n","                               dropout_p=0.5)\n","\n","modelConditioned.to(args.device)\n","\n","# optimizer\n","optimizer = optim.Adam(modelConditioned.parameters(), lr=args.learning_rate)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Device available  cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6vvzN2s37l1","executionInfo":{"status":"ok","timestamp":1604219392876,"user_tz":-420,"elapsed":245302,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"c3665d63-bb05-4618-9ee0-eca6b01940f1","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["248ca61c115043d298f8bf2b63f2824b","2027b822b5b24a238873433857c81d17","b2649f4d3ff4428381c50ee7457ff54e","d539be6c6bc54922a553177815cd9a4c","62e36471886a45d4abf3c140ce63f53a","60460b670784487f95e7f68320205c05","bc09a5e529b346e7996dfd5090163b6c","e0da435e39734c94b8cafacef5bd0123","cf9c0f5717854e5fa67c1b58921a7f53","4d53b0c7c6d9479b89d97b09589f2cf5","1a9b10df8ae34f689cf6b230573cc25c","ad0b7c58593a49f7be96fbaed33149e1","d92d5cfe9cc74a99aa122323210dad0c","acf5001d378d4fd6b76c1c97d89a60f1","f45d07beb35e4fc8813ee01b37481d0f","8f30711aa2c34d8f9ec61e62a6551abf","465d9f7c961e43e3967d6f8db646c3a6","8c20e9fd3e1644c0909f07cbc28cd6aa","a40564bd1d894770a2330343bb2e78ab","bb296ed0ebe34279b2a78b8039c6b649","565ead1fbe3a47d9b5632c02b0399763","a0054db0dcd9429ba51f23b963d0bef9","ac2c54ea135943439680c57de791abca","60fc6c3a0f934c0a90073a132d5fcacc"]}},"source":["mask_index = vectorizer.char_vocab.mask_index\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size)-1, \n","                          position=1, \n","                          leave=True)\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size)-1, \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","    for epoch_index in range(args.num_epochs):\n","        train_state['epoch_index'] = epoch_index\n","\n","        # Iterate over training dataset\n","\n","        # setup: batch generator, set loss and acc to 0, set train mode on\n","        dataset.set_split('train')\n","        batch_generator = generate_batches(dataset, \n","                                           batch_size=args.batch_size, \n","                                           device=args.device)\n","        running_loss = 0.0\n","        running_acc = 0.0\n","        modelConditioned.train()\n","        \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # the training routine is these 5 steps:\n","\n","            # --------------------------------------    \n","            # step 1. zero the gradients\n","            optimizer.zero_grad()\n","\n","            # step 2. compute the output\n","            y_pred = modelConditioned(x_in=batch_dict['x_data'],\n","                           nationality_index=batch_dict['class_index'])\n","\n","            # step 3. compute the loss\n","            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","\n","            # step 4. use loss to produce gradients\n","            loss.backward()\n","\n","            # step 5. use optimizer to take gradient step\n","            optimizer.step()\n","            # -----------------------------------------\n","            # compute the  running loss and running accuracy\n","            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","            running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","            # update bar\n","            train_bar.set_postfix(loss=running_loss,\n","                                  acc=running_acc,\n","                                  epoch=epoch_index)\n","            train_bar.update()\n","\n","        train_state['train_loss'].append(running_loss)\n","        train_state['train_acc'].append(running_acc)\n","\n","        # Iterate over val dataset\n","\n","        # setup: batch generator, set loss and acc to 0; set eval mode on\n","        dataset.set_split('val')\n","        batch_generator = generate_batches(dataset, \n","                                           batch_size=args.batch_size, \n","                                           device=args.device)\n","        running_loss = 0.\n","        running_acc = 0.\n","        modelConditioned.eval()\n","\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # compute the output\n","            y_pred = modelConditioned(x_in=batch_dict['x_data'],\n","                           nationality_index=batch_dict['class_index'])\n","\n","            # step 3. compute the loss\n","            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","            # compute the  running loss and running accuracy\n","            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","            running_acc += (acc_t - running_acc) / (batch_index + 1)\n","            \n","            # Update bar\n","            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                            epoch=epoch_index)\n","            val_bar.update()\n","\n","        train_state['val_loss'].append(running_loss)\n","        train_state['val_acc'].append(running_acc)\n","        \n","        # move model to cpu for sampling\n","        modelConditioned = modelConditioned.cpu()\n","        sampled_surnames = decode_samples(\n","            sample_from_model(modelConditioned, vectorizer, num_samples=2), \n","            vectorizer)\n","        epoch_bar.set_postfix(sample1=sampled_surnames[0], \n","                              sample2=sampled_surnames[1])\n","        # move model back to whichever device it should be on\n","        modelConditioned = modelConditioned.to(args.device)\n","        \n","        train_bar.n = 0\n","        val_bar.n = 0\n","        epoch_bar.update()\n","        \n","except KeyboardInterrupt:\n","    print(\"Exiting loop\")"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248ca61c115043d298f8bf2b63f2824b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf9c0f5717854e5fa67c1b58921a7f53","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"465d9f7c961e43e3967d6f8db646c3a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=11.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"rcHfkpKBu6gA"},"source":["## Test and Inference\n"]},{"cell_type":"code","metadata":{"id":"1aZrKLE1u9Ac","executionInfo":{"status":"ok","timestamp":1604217422892,"user_tz":-420,"elapsed":1096,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"c8ed9b27-9227-49bc-9062-59f3088d0c2d","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Unconditioned Model Inference\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","running_acc = 0.\n","model.eval()\n","\n","for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute the output\n","    y_pred = model(x_in=batch_dict['x_data'])\n","\n","    # compute the loss\n","    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","    # compute the accuracy\n","    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","\n","    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","    running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","train_state['test_loss'] = running_loss\n","train_state['test_acc'] = running_acc\n","\n","print(\"Test loss: {};\".format(train_state['test_loss']))\n","print(\"Test Accuracy: {}\".format(train_state['test_acc']))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Test loss: 2.2440438270568848;\n","Test Accuracy: 33.96681123933363\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AgY9Z9iR_It7","executionInfo":{"status":"ok","timestamp":1604220487922,"user_tz":-420,"elapsed":1719,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"2146b0f2-39cb-49b8-b042-a24dcb37c29d","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Conditioned Model Inference\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","running_acc = 0.\n","modelConditioned.eval()\n","\n","for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute the output\n","    y_pred = modelConditioned(x_in=batch_dict['x_data'],\n","                              nationality_index=batch_dict['class_index'])\n","\n","    # compute the loss\n","    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n","\n","    # compute the accuracy\n","    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n","\n","    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n","    running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","train_state['test_loss'] = running_loss\n","train_state['test_acc'] = running_acc\n","\n","print(\"Test loss: {};\".format(train_state['test_loss']))\n","print(\"Test Accuracy: {}\".format(train_state['test_acc']))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Test loss: 2.0347665548324585;\n","Test Accuracy: 38.65099595947546\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a-0bnNdevHn8","executionInfo":{"status":"ok","timestamp":1604217429104,"user_tz":-420,"elapsed":1117,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"448b0ee5-1516-4b42-a8e5-9e3763e58f48","colab":{"base_uri":"https://localhost:8080/"}},"source":["# unconditioned Model\n","# number of names to generate\n","num_names = 10\n","model = model.cpu()\n","# Generate nationality hidden state\n","sampled_surnames = decode_samples(\n","    sample_from_model(model, vectorizer, num_samples=num_names), \n","    vectorizer)\n","# Show results\n","print (\"-\"*15)\n","for i in range(num_names):\n","    print (sampled_surnames[i])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["---------------\n","Kafbull\n","Fumanov\n","Baaz\n","Gheanniksi\n","Amner\n","Eszymov\n","Moeros\n","Kansay\n","Armas\n","Ayallshi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7_sAajbi_lyg","executionInfo":{"status":"ok","timestamp":1604220770235,"user_tz":-420,"elapsed":1770,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"a6098e2c-f17b-4666-bc7d-3cffe5013461","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Conditioned Model\n","def sample_from_conditioned_model(model, vectorizer, nationalities, sample_size=20, \n","                      temperature=1.0):\n","    \"\"\"Sample a sequence of indices from the model\n","    \n","    Args:\n","        model (SurnameGenerationModel): the trained model\n","        vectorizer (SurnameVectorizer): the corresponding vectorizer\n","        nationalities (list): a list of integers representing nationalities\n","        sample_size (int): the max length of the samples\n","        temperature (float): accentuates or flattens \n","            the distribution. \n","            0.0 < temperature < 1.0 will make it peakier. \n","            temperature > 1.0 will make it more uniform\n","    Returns:\n","        indices (torch.Tensor): the matrix of indices; \n","        shape = (num_samples, sample_size)\n","    \"\"\"\n","    num_samples = len(nationalities)\n","    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n","                       for _ in range(num_samples)]\n","    begin_seq_index = torch.tensor(begin_seq_index, \n","                                   dtype=torch.int64).unsqueeze(dim=1)\n","    indices = [begin_seq_index]\n","    nationality_indices = torch.tensor(nationalities, dtype=torch.int64).unsqueeze(dim=0)\n","    h_t = model.nation_embedding(nationality_indices)\n","    \n","    for time_step in range(sample_size):\n","        x_t = indices[time_step]\n","        x_emb_t = model.char_emb(x_t)\n","        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n","        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n","        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n","        indices.append(torch.multinomial(probability_vector, num_samples=1))\n","    indices = torch.stack(indices).squeeze().permute(1, 0)\n","    return indices\n","\n","\n","modelConditioned = modelConditioned.cpu()\n","for index in range(len(vectorizer.nationality_vocab)):\n","    nationality = vectorizer.nationality_vocab.lookup_index(index)\n","    print(\"Sampled for {}: \".format(nationality))\n","    sampled_indices = sample_from_conditioned_model(modelConditioned, vectorizer,  \n","                                        nationalities=[index] * 3, \n","                                        temperature=0.7)\n","    for sampled_surname in decode_samples(sampled_indices, vectorizer):\n","        print(\"-  \" + sampled_surname)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Sampled for Arabic: \n","-  Saliba\n","-  Hasel\n","-  Kiif\n","Sampled for Chinese: \n","-  Kui\n","-  Chin\n","-  Son\n","Sampled for Czech: \n","-  Slak\n","-  Schore\n","-  Schinlan\n","Sampled for Dutch: \n","-  Ranrsech\n","-  Tone\n","-  Siepa\n","Sampled for English: \n","-  Ratser\n","-  Roin\n","-  Crisel\n","Sampled for French: \n","-  Pieher\n","-  Gilraich\n","-  Deranson\n","Sampled for German: \n","-  Shrowsing\n","-  Setganrer\n","-  Trats\n","Sampled for Greek: \n","-  Boikopas\n","-  Motitaos\n","-  Hatisos\n","Sampled for Irish: \n","-  Sindrer\n","-  Mockous\n","-  O'Millin\n","Sampled for Italian: \n","-  Marisa\n","-  Cermichi\n","-  Albba\n","Sampled for Japanese: \n","-  Nika\n","-  Kino\n","-  Tokara\n","Sampled for Korean: \n","-  Beud\n","-  Min\n","-  Wing\n","Sampled for Polish: \n","-  Maichev\n","-  Abalov\n","-  Janka\n","Sampled for Portuguese: \n","-  Arelo\n","-  Pigare\n","-  Merso\n","Sampled for Russian: \n","-  Aberkin\n","-  Avellin\n","-  Jisakov\n","Sampled for Scottish: \n","-  Wellet\n","-  Traed\n","-  Khiman\n","Sampled for Spanish: \n","-  Tralanes\n","-  Marta\n","-  Méra\n","Sampled for Vietnamese: \n","-  Luu\n","-  Trow\n","-  Lavs\n"],"name":"stdout"}]}]}
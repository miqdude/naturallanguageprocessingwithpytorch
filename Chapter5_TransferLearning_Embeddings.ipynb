{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter5_TransferLearning_Embeddings.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1isu7cw3egS4Mstc31HgiBn3aJghEV_86","authorship_tag":"ABX9TyMPPL0RAlzWU7114Pv7zCbg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8153395aaa294d73a73fb1a2e1f2b807":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_df8de38547524d66854f2f325b3531ec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6542b5958df848f7a0c37c482de54712","IPY_MODEL_b92c281ad96844df8533588cc770b286"]}},"df8de38547524d66854f2f325b3531ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6542b5958df848f7a0c37c482de54712":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5a0604f7145340e7a632ed90636296f1","_dom_classes":[],"description":"training routine:   0%","_model_name":"FloatProgressModel","bar_style":"","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9eac9514552b4aa090aa39a1ed904e48"}},"b92c281ad96844df8533588cc770b286":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44a8cced064e482ab3b7755954512d3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/100 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6037fa17d8c5488780d12467e25b3acc"}},"5a0604f7145340e7a632ed90636296f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9eac9514552b4aa090aa39a1ed904e48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44a8cced064e482ab3b7755954512d3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6037fa17d8c5488780d12467e25b3acc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"645dea5dcc784b00927e486ff80175ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_981d9c88ece848b38c58a892692880c5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_71bf33eaa7e34a448532716482a861cf","IPY_MODEL_f7fed69729184040a1c30c335412b5c5"]}},"981d9c88ece848b38c58a892692880c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71bf33eaa7e34a448532716482a861cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bb32df029f1426583c13f24a053792a","_dom_classes":[],"description":"split=train:  75%","_model_name":"FloatProgressModel","bar_style":"","max":655,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":490,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce2b511986a949de8c927e45a1645e03"}},"f7fed69729184040a1c30c335412b5c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffeae13c003e4fbe8e14c14e113a98ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 490/655 [00:13&lt;00:04, 38.66it/s, acc=60.5, epoch=0, loss=0.935]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a411ecc9502d44c496703f5161da5cc6"}},"0bb32df029f1426583c13f24a053792a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce2b511986a949de8c927e45a1645e03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffeae13c003e4fbe8e14c14e113a98ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a411ecc9502d44c496703f5161da5cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8f879f168c74fd2a329b25fd1893be8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_43d303d1e76541858cffdb6c8cf28a8b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fe5a0438bcaf4152890142de11bc0143","IPY_MODEL_5d5bd0076c4d45489bc99531aad51baf"]}},"43d303d1e76541858cffdb6c8cf28a8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe5a0438bcaf4152890142de11bc0143":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba54e9e0959841e3b20c624b74d24606","_dom_classes":[],"description":"split=val:   0%","_model_name":"FloatProgressModel","bar_style":"","max":139,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c85c472495fa41be91b66dd2adf656e6"}},"5d5bd0076c4d45489bc99531aad51baf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45dc4b9f19f34b568aecc444b0dab60c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/139 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5faf425b6d5e4a809aa6ee5f14e129a4"}},"ba54e9e0959841e3b20c624b74d24606":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c85c472495fa41be91b66dd2adf656e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45dc4b9f19f34b568aecc444b0dab60c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5faf425b6d5e4a809aa6ee5f14e129a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"G0lAETulEGkL"},"source":["# Transer Learning Word Embeddings"]},{"cell_type":"code","metadata":{"id":"fl7oHSuXAT0t","executionInfo":{"status":"ok","timestamp":1604440798615,"user_tz":-420,"elapsed":6810,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["import numpy as np\n","from collections import Counter\n","import string\n","import torch\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from argparse import Namespace\n","import torch.optim as optim\n","from tqdm.notebook import tqdm\n","import torch.nn.functional as F\n","import re"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFOq627nDD1S"},"source":["## Sequence Vocabulary\n"]},{"cell_type":"code","metadata":{"id":"tf9N8vLDDDdg","executionInfo":{"status":"ok","timestamp":1604440806540,"user_tz":-420,"elapsed":1602,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class SequenceVocabulary(object):\n","    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n","    \n","    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n","        if token_to_idx is None:\n","            token_to_idx = {}\n","        self._token_to_idx = token_to_idx\n","        \n","        self._idx_to_token = {\n","            idx: token for token, idx in self._token_to_idx.items()\n","        }\n","        \n","        self._add_unk = add_unk\n","        self._unk_token = unk_token\n","        self._mask_token = mask_token\n","        \n","        # add begin and end sequence token\n","        self._begin_of_seq_token = \"<BEGIN-OF-SEQUENCE>\"\n","        self._end_of_seq_token = \"<END-OF-SEQUENCE>\"\n","        \n","        self.begin_seq_index = self.add_token(self._begin_of_seq_token)\n","        self.end_seq_index = self.add_token(self._end_of_seq_token)\n","\n","        self.mask_index = self.add_token(mask_token)\n","        self.unk_index = -1\n","        if add_unk:\n","            self.unk_index = self.add_token(unk_token)\n","            \n","    def to_serializeable(self):\n","        \"\"\"return a serializeable dictionary\"\"\"\n","        return {\n","            'token_to_idx': self._token_to_idx,\n","            'mask_token': self._mask_token,\n","            'add_unk': self._add_unk,\n","            'unk_token': self._unk_token\n","        }\n","    \n","    @classmethod\n","    def from_serializeable(cls, contents):\n","        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n","        return cls(**contents)\n","    \n","    def add_token(self, token):\n","        \"\"\"Add a token and return it's index\"\"\"\n","        if token in self._token_to_idx:\n","            index = self._token_to_idx[token]\n","        else:\n","            index = len(self._token_to_idx)\n","            self._token_to_idx[token] = index\n","            self._idx_to_token[index] = token\n","        return index\n","    \n","    def lookup_token(self, token):\n","        \"\"\"get the index of a token \n","        if not exist returns the unk_index\"\"\"\n","        if self.unk_index >= 0:\n","            return self._token_to_idx.get(token, self.unk_index)\n","        else:\n","            return self._token_to_idx[token]\n","        \n","    def lookup_index(self, index):\n","        if index not in self._idx_to_token:\n","            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n","        return self._idx_to_token[index]\n","    \n","    def __str__(self):\n","        return \"<Vocabulary(size=%d)>\" % len(self)\n","    \n","    def __len__(self):\n","        return len(self._token_to_idx)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5E69s3EJJ12R"},"source":["## Vocabulary"]},{"cell_type":"code","metadata":{"id":"XZmm-Yw-J39b","executionInfo":{"status":"ok","timestamp":1604440808645,"user_tz":-420,"elapsed":1657,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["# create vocabulary class\n","class Vocabulary(object):\n","    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n","    \n","    def __init__(self, token_to_idx=None):\n","        if token_to_idx is None:\n","            token_to_idx = {}\n","        self._token_to_idx = token_to_idx\n","        \n","        self._idx_to_token = {\n","            idx: token for token, idx in self._token_to_idx.items()\n","        }\n","\n","    def to_serializeable(self):\n","        \"\"\"return a serializeable dictionary\"\"\"\n","        return {\n","            'token_to_idx': self._token_to_idx\n","        }\n","    \n","    @classmethod\n","    def from_serializeable(cls, contents):\n","        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n","        return cls(**contents)\n","    \n","    def add_token(self, token):\n","        \"\"\"Add a token and return it's index\"\"\"\n","        if token in self._token_to_idx:\n","            index = self._token_to_idx[token]\n","        else:\n","            index = len(self._token_to_idx)\n","            self._token_to_idx[token] = index\n","            self._idx_to_token[index] = token\n","        return index\n","    \n","    def lookup_token(self, token):\n","        \"\"\"get the index of a token \n","        if not exist returns the unk_index\"\"\"\n","        return self._token_to_idx[token]\n","        \n","    def lookup_index(self, index):\n","        if index not in self._idx_to_token:\n","            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n","        return self._idx_to_token[index]\n","    \n","    def __str__(self):\n","        return \"<Vocabulary(size=%d)>\" % len(self)\n","    \n","    def __len__(self):\n","        return len(self._token_to_idx)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bc0_OvtGEB3Y"},"source":["## Vectorizer"]},{"cell_type":"code","metadata":{"id":"ajnyzs_oEDtZ","executionInfo":{"status":"ok","timestamp":1604440809686,"user_tz":-420,"elapsed":694,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class NewsVectorizer(object):\n","    def __init__(self, title_vocab, category_vocab):\n","        self.title_vocab = title_vocab\n","        self.category_vocab = category_vocab\n","\n","    def vectorize(self, title, vector_length=-1):\n","        indices = [self.title_vocab.begin_seq_index]\n","        indices.extend(self.title_vocab.lookup_token(token)\n","                    for token in title.split(\" \"))\n","        indices.append(self.title_vocab.end_seq_index)\n","\n","        if vector_length < 0:\n","            vector_length = len(indices)\n","\n","        # create vector representation\n","        out_vector = np.zeros(vector_length, dtype=np.int64)\n","        out_vector[:len(indices)] = indices\n","        out_vector[len(indices):] = self.title_vocab.mask_index\n","\n","        return out_vector\n","\n","    @classmethod\n","    def from_dataframe(cls, news_df, cutoff=25):\n","        category_vocab = Vocabulary()\n","        \n","        # add the categories to vocabulary\n","        for category in sorted(set(news_df.category)):\n","            category_vocab.add_token(category)\n","\n","        # count the frequency of each word in title\n","        word_counter = Counter()\n","        for title in news_df.title:\n","            for word in title.split(\" \"):\n","                if word not in string.punctuation:\n","                    word_counter[word] += 1\n","        \n","        # add word as token when it's more than cutoff\n","        title_vocab = SequenceVocabulary()\n","        for token, word_count in word_counter.items():\n","            if word_count > cutoff:\n","                title_vocab.add_token(token)\n","\n","        return cls(title_vocab, category_vocab)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7W32V6YrW7HN"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"BLfEHmYhW-dJ","executionInfo":{"status":"ok","timestamp":1604440812759,"user_tz":-420,"elapsed":1432,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class NewsDataset(Dataset):\n","    def __init__(self, news_df, vectorizer):\n","        self.news_df = news_df\n","        self._vectorizer = vectorizer\n","\n","        # calculate how long the sequence could be\n","        # max_seq_length is added by 2 since using\n","        # begin and end seq token\n","        measure_len = lambda context: len(context.split(\" \"))\n","        self._max_seq_length = max(map(measure_len, news_df.title)) + 2\n","        \n","        self.train_df = self.news_df[self.news_df.split == 'train']\n","        self.train_size = len(self.train_df)\n","        \n","        self.val_df = self.news_df[self.news_df.split == 'val']\n","        self.val_size = len(self.val_df)\n","        \n","        self.test_df = self.news_df[self.news_df.split == 'test']\n","        self.test_size = len(self.test_df)\n","        \n","        self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                            'val': (self.val_df, self.val_size),\n","                            'test': (self.test_df, self.test_size)}\n","        \n","        self.set_split('train')\n","\n","        # Class weights\n","        class_counts = news_df.category.value_counts().to_dict()\n","        def sort_key(item):\n","            return self._vectorizer.category_vocab.lookup_token(item[0])\n","        sorted_counts = sorted(class_counts.items(), key=sort_key)\n","        frequencies = [count for _, count in sorted_counts]\n","        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n","        \n","    @classmethod\n","    def load_dataset_and_make_vectorizer(cls, news_csv, cuda=False):\n","        \"\"\"Load dataset from csv and returns the dataset object\n","        and vectorizer\"\"\"\n","        news_df = pd.read_csv(news_csv)\n","        train_news_df = news_df[news_df.split == 'train']\n","        return cls(news_df,\n","                   NewsVectorizer.from_dataframe(train_news_df))\n","    \n","    def get_vectorizer(self):\n","        \"\"\"Get vectorizer\"\"\"\n","        return self._vectorizer\n","    \n","    def set_split(self, split='train'):\n","        \"\"\"Set the split from data\"\"\"\n","        self._target_split = split\n","        self._target_df, self._target_size = self._lookup_dict[split]\n","        \n","    def __len__(self):\n","        return self._target_size\n","    \n","    def __getitem__(self, index):\n","        \"\"\"the primary entry point method for PyTorch datasets\n","        Args:\n","            index (int): the index to the data point\n","        Returns:\n","            a dict of the data point's features (x_data) and label (y_target)\n","        \"\"\"\n","        row = self._target_df.iloc[index]\n","        \n","        title_vector = self._vectorizer.vectorize(row.title,\n","                                                    self._max_seq_length)\n","        category_index = self._vectorizer.category_vocab.lookup_token(row.category)\n","        \n","        return {\n","            'x_data' : title_vector,\n","            'y_target' : category_index\n","        }\n","    \n","    def get_num_batches(self, batch_size):\n","        \"\"\"Given the batch size return the number of batches in the dataset\"\"\"\n","        return len(self) // batch_size"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0oUfbhVccWbG"},"source":["## Frakenstein Classification CNN Class"]},{"cell_type":"code","metadata":{"id":"wCt8n-0TcV8A","executionInfo":{"status":"ok","timestamp":1604440819781,"user_tz":-420,"elapsed":3373,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class NewsClassifier(nn.Module):\n","    def __init__(self, embedding_size, num_embeddings,\n","                 num_channels, hidden_dim, num_classes,\n","                 dropout_p, pretrained_embeddings= None,\n","                 padding_idx=0):\n","        super(NewsClassifier, self).__init__()\n","\n","        if pretrained_embeddings is None:\n","            self.emb = nn.Embedding(embedding_dim= embedding_size,\n","                                    num_embeddings= num_embeddings,\n","                                    padding_idx= padding_idx)\n","        else:\n","            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n","            self.emb = nn.Embedding(embedding_dim= embedding_size,\n","                                    num_embeddings= num_embeddings,\n","                                    padding_idx= padding_idx,\n","                                    _weight= pretrained_embeddings)\n","            \n","        # create the network\n","        self.convnet = nn.Sequential(\n","            nn.Conv1d(in_channels=embedding_size, \n","                   out_channels=num_channels, kernel_size=3),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n","                   kernel_size=3, stride=2),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n","                   kernel_size=3, stride=2),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n","                   kernel_size=3),\n","            nn.ELU()\n","        )\n","\n","        self._dropout_p = dropout_p\n","        self.fc1 = nn.Linear(num_channels, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, x_in, apply_softmax=False):\n","        # embed and permute so features are channels\n","        x_embedded = self.emb(x_in).permute(0, 2, 1)\n","\n","        features = self.convnet(x_embedded)\n","\n","        # average and remove the extra dimension\n","        remaining_size = features.size(dim=2)\n","        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n","        features = F.dropout(features, p=self._dropout_p)\n","        \n","        # mlp classifier\n","        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n","        prediction_vector = self.fc2(intermediate_vector)\n","\n","        if apply_softmax:\n","            prediction_vector = F.softmax(prediction_vector, dim=1)\n","\n","        return prediction_vector"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEheufCVkdd8"},"source":["## Helper Functions"]},{"cell_type":"code","metadata":{"id":"NVOui7zKkiBq","executionInfo":{"status":"ok","timestamp":1604440819783,"user_tz":-420,"elapsed":914,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["def load_glove_from_file(file_path):\n","    word_to_index = {}\n","    embeddings = []\n","\n","    with open(file_path) as fp:\n","        for index, line in enumerate(fp):\n","            line = line.split(\" \")\n","            word = line[0]\n","            embedding = [float(var) for var in line[1:]]\n","            embeddings.append(embedding)\n","    \n","    return word_to_index, np.stack(embeddings)\n","\n","def make_embedding_matrix(file_path, words):\n","    word_to_index, embeddings = load_glove_from_file(file_path)\n","    embedding_size = embeddings.shape[1]\n","    final_embeddings = np.zeros(len(words), embedding_size)\n","\n","    for i, word in enumerate(words):\n","        if word in word_to_index:\n","            final_embeddings[i, :] = embeddings[word_to_index[word]]\n","        else:\n","            embedding_i = torch.ones(1, embedding_size)\n","            torch.nn.init.xavier_uniform_(embedding_i)\n","            final_embeddings[i, :] = embedding_i\n","\n","    return final_embeddings\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVSdBOhKQOVC"},"source":["## Training Routine\n"]},{"cell_type":"code","metadata":{"id":"Qv9mrCWQQQqc","executionInfo":{"status":"ok","timestamp":1604440823075,"user_tz":-420,"elapsed":1781,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["args = Namespace(\n","    # Data information\n","    frequency_cutoff = 25,\n","    model_state_file = '/content/drive/My Drive/Colab Notebooks/Data/model.pth',\n","    news_csv = '/content/drive/My Drive/Colab Notebooks/Data/news_with_splits.csv',\n","    save_dir = '/content/drive/My Drive/Colab Notebooks/Data',\n","    vectorizer_file = '/content/drive/My Drive/Colab Notebooks/Data/vectorizer.json',\n","    # Model HyperParameters\n","    embedding_size=300,\n","    glove_file = '/content/drive/My Drive/Colab Notebooks/Data/Glove/glove.6B.100d.txt',\n","    use_glove = False,\n","    hidden_dim = 100,\n","    num_channels = 100,\n","    # Training HyperParameters\n","    batch_size = 128,\n","    early_stopping_criteria=5,\n","    learning_rate=0.001,\n","    momentum=0.1,\n","    num_epochs=100,\n","    seed=1337,\n","    cuda=True,\n","    dropout=0.1\n",")\n","\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"):\n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will\n","    ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last)\n","\n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        for name, tensor in data_dict.items():\n","            out_data_dict[name] = data_dict[name].to(device)\n","        yield out_data_dict"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWGlpCvlRCgp","executionInfo":{"status":"ok","timestamp":1604440837116,"user_tz":-420,"elapsed":13543,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"dedd2032-b357-4ec0-9b0a-26a756f8a2de","colab":{"base_uri":"https://localhost:8080/"}},"source":["# create variables to record\n","# the training loop\n","def make_train_state(args):\n","    return {\n","        'epoch_index':0,\n","        'train_loss':[],\n","        'train_acc':[],\n","        'val_loss': [],\n","        'val_acc': [],\n","        'test_loss': -1,\n","        'test_acc': -1,\n","    }\n","\n","def compute_accuracy(y_pred, y_target):\n","    _, y_pred_indices = y_pred.max(dim=1)\n","    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","    return n_correct / len(y_pred_indices) * 100\n","\n","train_state = make_train_state(args)\n","\n","if torch.cuda.is_available() and args.cuda:\n","  args.cuda = True\n","else:\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Device available \", args.device)\n","\n","# dataset object\n","dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n","dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","# vectorizer\n","vectorizer = dataset.get_vectorizer()\n","\n","# Use GloVe or randomly initialized embeddings\n","if args.use_glove:\n","    words = vectorizer.title_vocab._token_to_idx.keys()\n","    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n","                                       words=words)\n","    print(\"Using pre-trained embeddings\")\n","else:\n","    print(\"Not using pre-trained embeddings\")\n","    embeddings = None\n","\n","# classifier\n","classifier = NewsClassifier(embedding_size=args.embedding_size, \n","                            num_embeddings=len(vectorizer.title_vocab),\n","                            num_channels=args.num_channels,\n","                            hidden_dim=args.hidden_dim, \n","                            num_classes=len(vectorizer.category_vocab), \n","                            dropout_p=args.dropout,\n","                            pretrained_embeddings=embeddings,\n","                            padding_idx=0)\n","classifier = classifier.to(args.device)\n","\n","# loss function and optimizer\n","loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","\n","print(\"Embedding dim \", args.embedding_size)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Device available  cuda\n","Not using pre-trained embeddings\n","Embedding dim  300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mfd5PlLORIF5","outputId":"baf54c79-93ec-4db3-ed37-4fe0f767e8e9","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["8153395aaa294d73a73fb1a2e1f2b807","df8de38547524d66854f2f325b3531ec","6542b5958df848f7a0c37c482de54712","b92c281ad96844df8533588cc770b286","5a0604f7145340e7a632ed90636296f1","9eac9514552b4aa090aa39a1ed904e48","44a8cced064e482ab3b7755954512d3c","6037fa17d8c5488780d12467e25b3acc","645dea5dcc784b00927e486ff80175ad","981d9c88ece848b38c58a892692880c5","71bf33eaa7e34a448532716482a861cf","f7fed69729184040a1c30c335412b5c5","0bb32df029f1426583c13f24a053792a","ce2b511986a949de8c927e45a1645e03","ffeae13c003e4fbe8e14c14e113a98ca","a411ecc9502d44c496703f5161da5cc6","a8f879f168c74fd2a329b25fd1893be8","43d303d1e76541858cffdb6c8cf28a8b","fe5a0438bcaf4152890142de11bc0143","5d5bd0076c4d45489bc99531aad51baf","ba54e9e0959841e3b20c624b74d24606","c85c472495fa41be91b66dd2adf656e6","45dc4b9f19f34b568aecc444b0dab60c","5faf425b6d5e4a809aa6ee5f14e129a4"]}},"source":["# Create training loop\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size)-1, \n","                          position=1, \n","                          leave=True)\n","\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size)-1, \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","    for epoch_index in range(args.num_epochs):\n","        train_state['epoch_index'] = epoch_index\n","        # setup batch generator\n","        # set loss and train mode on\n","        dataset.set_split('train')\n","        batch_generator = generate_batches(dataset=dataset,\n","                                        batch_size=args.batch_size,\n","                                        device=args.device)\n","      \n","        running_loss = 0.0\n","        running_acc = 0.0\n","        classifier.train()\n","      \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # step 1 zero the gradients\n","            optimizer.zero_grad()\n","          \n","            # step 2 compute the output\n","            y_pred = classifier(x_in=batch_dict['x_data'])\n","          \n","            # step 3 compute the loss\n","            loss = loss_func(y_pred, batch_dict['y_target'])\n","            loss_batch = loss.item()\n","            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","          \n","            # step 4 use loss to produce gradients\n","            loss.backward()\n","          \n","            # step 5 use optimizer to take the gradient step\n","            optimizer.step()\n","          \n","            # step 6 compute the acccuracy\n","            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","\n","            # update bar\n","            train_bar.set_postfix(loss=running_loss, \n","                                acc=running_acc, \n","                                epoch=epoch_index)\n","            train_bar.update()\n","          \n","        train_state['train_loss'].append(running_loss)\n","        train_state['train_acc'].append(running_acc)\n","      \n","        # Iterate over val dataset\n","        # setup: batch generator, set loss and acc to 0, set eval mode on\n","        dataset.set_split('val')\n","        batch_generator = generate_batches(dataset,\n","                                        batch_size=args.batch_size,\n","                                        device=args.device)\n","      \n","        running_loss = 0.\n","        running_acc = 0.\n","        classifier.eval()\n","      \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # step 1. compute the output\n","            y_pred = classifier(x_in=batch_dict['x_data'])\n","          \n","            # step 2. compute the loss\n","            loss = loss_func(y_pred, batch_dict['y_target'])\n","            loss_batch = loss.item()\n","            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","          \n","            # step 3. compute the accuracy\n","            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","            train_state['val_loss'].append(running_loss)\n","            train_state['val_acc'].append(running_acc)\n","            \n","            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                            epoch=epoch_index)\n","            val_bar.update()\n","          \n","        train_state['val_loss'].append(running_loss)\n","        train_state['val_acc'].append(running_acc)\n","\n","        train_bar.n = 0\n","        val_bar.n = 0\n","        epoch_bar.update()\n","except KeyboardInterrupt:\n","    print(\"Exiting loop\") "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8153395aaa294d73a73fb1a2e1f2b807","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"645dea5dcc784b00927e486ff80175ad","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=655.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8f879f168c74fd2a329b25fd1893be8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=139.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"zicDShWduJnO","executionInfo":{"status":"ok","timestamp":1603813302954,"user_tz":-420,"elapsed":5323,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"267f4207-97c1-49dc-f0ec-7db06ec053a8","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# evaluate the model\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset,\n","                                   args.batch_size,\n","                                   device=args.device)\n","\n","running_loss = 0.\n","running_acc = 0.\n","classifier.eval()\n","\n","for batch_index, batch_dict in enumerate(batch_generator):\n","  # compute the output\n","  y_pred = classifier(x_in=batch_dict['x_data'])\n","\n","  # compute the loss\n","  loss = loss_func(y_pred, batch_dict['y_target'])\n","  loss_batch = loss.item()\n","  running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","\n","  # compute the accuracy\n","  acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","  running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","\n","train_state['test_loss'] = running_loss\n","train_state['test_acc'] = running_acc\n","\n","print(\"Test loss : {:.3f}\".format(train_state['test_loss']))\n","print(\"Test acc : {:.3f}\".format(train_state['test_acc']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss : 3.563\n","Test acc : 76.897\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7QhvTuUduW3t","executionInfo":{"status":"ok","timestamp":1603813457602,"user_tz":-420,"elapsed":1774,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"97925409-4f54-43d6-ab49-16ce45fdef83","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# inference mode\n","# Preprocess the reviews\n","def preprocess_text(text):\n","    text = ' '.join(word.lower() for word in text.split(\" \"))\n","    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n","    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n","    return text\n","\n","def predict_category(title, classifier, vectorizer, max_length):\n","    \"\"\"Predict a News category for a new title\n","    \n","    Args:\n","        title (str): a raw title string\n","        classifier (NewsClassifier): an instance of the trained classifier\n","        vectorizer (NewsVectorizer): the corresponding vectorizer\n","        max_length (int): the max sequence length\n","            Note: CNNs are sensitive to the input data tensor size. \n","                  This ensures to keep it the same size as the training data\n","    \"\"\"\n","    title = preprocess_text(title)\n","    vectorized_title = \\\n","        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n","    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n","    probability_values, indices = result.max(dim=1)\n","    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n","\n","    return {'category': predicted_category, \n","            'probability': probability_values.item()}\n","\n","\n","def get_samples():\n","    samples = {}\n","    for cat in dataset.val_df.category.unique():\n","        samples[cat] = dataset.val_df.title[dataset.val_df.category==cat].tolist()[:5]\n","    return samples\n","\n","val_samples = get_samples()\n","\n","#title = input(\"Enter a news title to classify: \")\n","classifier = classifier.to(\"cpu\")\n","\n","for truth, sample_group in val_samples.items():\n","    print(f\"True Category: {truth}\")\n","    print(\"=\"*30)\n","    for sample in sample_group:\n","        prediction = predict_category(sample, classifier, \n","                                      vectorizer, dataset._max_seq_length + 1)\n","        print(\"Prediction: {} (p={:0.2f})\".format(prediction['category'],\n","                                                  prediction['probability']))\n","        print(\"\\t + Sample: {}\".format(sample))\n","    print(\"-\"*30 + \"\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True Category: Business\n","==============================\n","Prediction: Business (p=1.00)\n","\t + Sample: AZ suspends marketing of cancer drug\n","Prediction: Business (p=1.00)\n","\t + Sample: Business world has mixed reaction to Perez move\n","Prediction: Sports (p=1.00)\n","\t + Sample: Betting Against Bombay\n","Prediction: Sports (p=1.00)\n","\t + Sample: Malpractice Insurers Face a Tough Market\n","Prediction: Sports (p=0.51)\n","\t + Sample: NVIDIA Is Vindicated\n","------------------------------\n","\n","True Category: Sci/Tech\n","==============================\n","Prediction: Sci/Tech (p=0.99)\n","\t + Sample: Spies prize webcam #39;s eyes\n","Prediction: Sci/Tech (p=1.00)\n","\t + Sample: Sober worm causes headaches\n","Prediction: World (p=0.96)\n","\t + Sample: Local Search: Missing Pieces Falling into Place\n","Prediction: Sci/Tech (p=1.00)\n","\t + Sample: Hackers baiting Internet users with Beckham pix\n","Prediction: Sci/Tech (p=0.98)\n","\t + Sample: Nokia adds BlackBerry support to Series 80 handsets\n","------------------------------\n","\n","True Category: Sports\n","==============================\n","Prediction: Sci/Tech (p=1.00)\n","\t + Sample: Is Meyer the man to get Irish up?\n","Prediction: World (p=0.86)\n","\t + Sample: Who? Who? And Clemens\n","Prediction: Sports (p=1.00)\n","\t + Sample: Baseball Today (AP)\n","Prediction: Business (p=1.00)\n","\t + Sample: Mark Kreidler: Yao Ming epitomizes the Chinese athlete who is &lt;b&gt;...&lt;/b&gt;\n","Prediction: Sports (p=1.00)\n","\t + Sample: No. 5 Miami Rebounds to Beat FSU in Overtime\n","------------------------------\n","\n","True Category: World\n","==============================\n","Prediction: Sports (p=1.00)\n","\t + Sample: Arafat in pain but expected to recover-Shaath\n","Prediction: World (p=1.00)\n","\t + Sample: Maoist rebels bomb Kathmandu building, no injuries (Reuters)\n","Prediction: World (p=1.00)\n","\t + Sample: Son Running for Ill. Rep.'s House Seat (AP)\n","Prediction: World (p=0.77)\n","\t + Sample: Strong Quake Hits in Japan\n","Prediction: World (p=1.00)\n","\t + Sample: Israel assassinates Hamas militant in Damascus\n","------------------------------\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T9BHJ8nU1WbB","executionInfo":{"status":"ok","timestamp":1603815310429,"user_tz":-420,"elapsed":1614,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"a13d0c3e-ae38-4a61-f088-5e30b090be36","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["categories = vectorizer.category_vocab._token_to_idx.keys()\n","print(\"Available categories \", categories)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Available categories  dict_keys(['Business', 'Sci/Tech', 'Sports', 'World'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1BLvPk6u9zM","executionInfo":{"status":"ok","timestamp":1603815129168,"user_tz":-420,"elapsed":63507,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"22a53c93-f1b9-4fbc-b15e-3557b04c2b76","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["title = input(\"enter news title :\")\n","prediction = predict_category(title, classifier, \n","                                      vectorizer, dataset._max_seq_length + 1)\n","print(\"Prediction: {} (p={:0.2f})\".format(prediction['category'],\n","                                            prediction['probability']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["enter news title :What the world's most overtouristed destinations look like now\n","Prediction: Sci/Tech (p=1.00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73WE1Z_DHdGv"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"b2h9CbwuHgrV","executionInfo":{"status":"error","timestamp":1604440777555,"user_tz":-420,"elapsed":1743,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"24091717-24ee-45dc-b77b-483c036ee27e","colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["def get_source_sentence(vectorizer, batch_dict, index):\n","    indices = batch_dict['x_source'][index].cpu().data.numpy()\n","    vocab = vectorizer.source_vocab\n","    return sentence_from_indices(indices, vocab)\n","\n","def get_true_sentence(vectorizer, batch_dict, index):\n","    return sentence_from_indices(batch_dict['y_target'].cpu().data.numpy()[index], vectorizer.target_vocab)\n","    \n","def get_sampled_sentence(vectorizer, batch_dict, index):\n","    y_pred = model(x_source=batch_dict['x_source'], \n","                   x_source_lengths=batch_dict['x_source_length'], \n","                   target_sequence=batch_dict['x_target'])\n","    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab)\n","\n","def get_all_sentences(vectorizer, batch_dict, index):\n","    return {\"source\": get_source_sentence(vectorizer, batch_dict, index), \n","            \"truth\": get_true_sentence(vectorizer, batch_dict, index), \n","            \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index)}\n","    \n","def sentence_from_indices(indices, vocab, strict=True):\n","    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n","    out = []\n","    for index in indices:\n","        if index == vocab.begin_seq_index and strict:\n","            continue\n","        elif index == vocab.end_seq_index and strict:\n","            return \" \".join(out)\n","        else:\n","            out.append(vocab.lookup_index(index))\n","    return \" \".join(out)\n","\n","\n","\n","\n","dataset.set_split('val')\n","batch_generator = generate_nmt_batches(dataset, \n","                                       batch_size=args.batch_size, \n","                                       device=args.device)\n","batch_dict = next(batch_generator)\n","results = get_all_sentences(vectorizer, batch_dict, 1)\n","results"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3cd822fd9c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m batch_generator = generate_nmt_batches(dataset, \n\u001b[1;32m     37\u001b[0m                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}]}]}
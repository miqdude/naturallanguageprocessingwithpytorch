{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter5_CBOW_Embeddings.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1ZyKxy7y6SYLGvEgiYUTBa8-qOQoNuMz1","authorship_tag":"ABX9TyOZiYKxiXCx45b6YTh0zWRH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dd6361e5683b4b61a360684e47e575d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_04d6dd657ea843dd9cdcd854479d3c9a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e178d5fcf23b460785143e9fa5bb9aaa","IPY_MODEL_7929cbb3bb384b7dafbb1984641b3180"]}},"04d6dd657ea843dd9cdcd854479d3c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e178d5fcf23b460785143e9fa5bb9aaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b7f665c3f18c42d48bb609db739e93df","_dom_classes":[],"description":"training routine: 100%","_model_name":"FloatProgressModel","bar_style":"","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1efbdf1a68cf462b80f8634f611ea093"}},"7929cbb3bb384b7dafbb1984641b3180":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03bf28eb68924ab49f1b097f9f0ccda9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100/100 [22:33&lt;00:00, 13.12s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fda08123b0f4f4f9ad6dccd190f6c52"}},"b7f665c3f18c42d48bb609db739e93df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1efbdf1a68cf462b80f8634f611ea093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03bf28eb68924ab49f1b097f9f0ccda9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2fda08123b0f4f4f9ad6dccd190f6c52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a8e971e40a24a489d3ca2ec3e961c41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_65e3b80fc66b4955851b8b0195154331","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1dd36a31f704c628e77a6cf0b8f4bee","IPY_MODEL_bc91e6f8924041de97bdb26e878db527"]}},"65e3b80fc66b4955851b8b0195154331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1dd36a31f704c628e77a6cf0b8f4bee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d858579e54c74ea39348c21a2616f290","_dom_classes":[],"description":"split=train: 100%","_model_name":"FloatProgressModel","bar_style":"","max":495,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":495,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f86921073cf4145b3a76b13fe9430ef"}},"bc91e6f8924041de97bdb26e878db527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5899274073364ea7810f5a8fdc3325b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 495/495 [22:30&lt;00:00, 43.95it/s, acc=83.4, epoch=99, loss=1.08]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e512d420b31489f8ada44aba880dfee"}},"d858579e54c74ea39348c21a2616f290":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f86921073cf4145b3a76b13fe9430ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5899274073364ea7810f5a8fdc3325b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e512d420b31489f8ada44aba880dfee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aca67995d7fa4f8190ca42259b3aae05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_42130394980a4d04aa32a22a87790f1f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ef36fd0e4ceb40c3963b3c0a9550a200","IPY_MODEL_c71f54c2f1454767989117a790ca6438"]}},"42130394980a4d04aa32a22a87790f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef36fd0e4ceb40c3963b3c0a9550a200":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d0310f6ac26245b790e5f579848ba469","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":105,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":105,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30db7b30112d44a39e7cf92b83953f06"}},"c71f54c2f1454767989117a790ca6438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5035919f9f5f450e827fc851ecc7dab5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 105/105 [22:33&lt;00:00, 10.04s/it, acc=12.4, epoch=99, loss=15.9]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7a893ff91f6452bbef0474349fd3699"}},"d0310f6ac26245b790e5f579848ba469":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30db7b30112d44a39e7cf92b83953f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5035919f9f5f450e827fc851ecc7dab5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7a893ff91f6452bbef0474349fd3699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"K7LxLUwZUNQd"},"source":["# CBOW Word Embeddings"]},{"cell_type":"code","metadata":{"id":"UsLhQYOiTTob","executionInfo":{"status":"ok","timestamp":1603758109266,"user_tz":-420,"elapsed":4748,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["import numpy as np\n","from collections import Counter\n","import string\n","import torch\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from argparse import Namespace\n","import torch.optim as optim\n","from tqdm.notebook import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QyLLJv4KUJlE"},"source":["## Vocabulary\n"]},{"cell_type":"code","metadata":{"id":"EaeGATILTkKu","executionInfo":{"status":"ok","timestamp":1603758327236,"user_tz":-420,"elapsed":1416,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["# create vocabulary class\n","class Vocabulary(object):\n","    \"\"\"Class to extract and process vocabularies for mapping\"\"\"\n","    \n","    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n","        if token_to_idx is None:\n","            token_to_idx = {}\n","        self._token_to_idx = token_to_idx\n","        \n","        self._idx_to_token = {\n","            idx: token for token, idx in self._token_to_idx.items()\n","        }\n","        \n","        self._add_unk = add_unk\n","        self._unk_token = unk_token\n","        self._mask_token = mask_token\n","        \n","        self.mask_index = self.add_token(mask_token)\n","        self.unk_index = -1\n","        if add_unk:\n","            self.unk_index = self.add_token(unk_token)\n","            \n","    def to_serializeable(self):\n","        \"\"\"return a serializeable dictionary\"\"\"\n","        return {\n","            'token_to_idx': self._token_to_idx,\n","            'mask_token': self._mask_token,\n","            'add_unk': self._add_unk,\n","            'unk_token': self._unk_token\n","        }\n","    \n","    @classmethod\n","    def from_serializeable(cls, contents):\n","        \"\"\"create vocabulary object from serialize dictionary\"\"\"\n","        return cls(**contents)\n","    \n","    def add_token(self, token):\n","        \"\"\"Add a token and return it's index\"\"\"\n","        if token in self._token_to_idx:\n","            index = self._token_to_idx[token]\n","        else:\n","            index = len(self._token_to_idx)\n","            self._token_to_idx[token] = index\n","            self._idx_to_token[index] = token\n","        return index\n","    \n","    def lookup_token(self, token):\n","        \"\"\"get the index of a token \n","        if not exist returns the unk_index\"\"\"\n","        if self.unk_index >= 0:\n","            return self._token_to_idx.get(token, self.unk_index)\n","        else:\n","            return self._token_to_idx[token]\n","        \n","    def lookup_index(self, index):\n","        if index not in self._idx_to_token:\n","            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n","        return self._idx_to_token[index]\n","    \n","    def __str__(self):\n","        return \"<Vocabulary(size=%d)>\" % len(self)\n","    \n","    def __len__(self):\n","        return len(self._token_to_idx)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VOqsG1eDUT65"},"source":["## Vetorizer\n"]},{"cell_type":"code","metadata":{"id":"oHR0x16YUYIX","executionInfo":{"status":"ok","timestamp":1603758330767,"user_tz":-420,"elapsed":2291,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class CBOWVectorizer(object):\n","    def __init__(self, cbow_vocab):\n","        self.cbow_vocab = cbow_vocab\n","        \n","    def vectorize(self, context, vector_length=-1):\n","        \"\"\"Create one_hot vector for review\n","        Args:\n","            surname (str): the surname\n","        Returns:\n","            one_hot_matrix (ndarray): matrix of one hot vectors\n","        \"\"\"\n","        # tokenize the context\n","        indices = [self.cbow_vocab.lookup_token(token) for token in context.split(\" \")]\n","        if vector_length < 0:\n","            vector_length = len(indices)\n","        \n","        # create vector representation\n","        out_vector = np.zeros(vector_length, dtype=np.int64)\n","        out_vector[:len(indices)] = indices\n","        out_vector[len(indices):] = self.cbow_vocab.mask_index\n","\n","        return out_vector\n","    \n","    @classmethod\n","    def from_dataframe(cls, dataframe, cutoff=25):\n","        \"\"\"Instantiate a ReviewVector from dataset\"\"\"\n","        \n","        cbow_vocab = Vocabulary()\n","        \n","        for index, row in dataframe.iterrows():\n","            for word in row.context.split(' '):\n","                cbow_vocab.add_token(word)\n","            cbow_vocab.add_token(row.target)\n","            \n","        return cls(cbow_vocab)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PwSFRAQiX0n7"},"source":["## CBOW Dataset"]},{"cell_type":"code","metadata":{"id":"hnvE3IbZX3Ae","executionInfo":{"status":"ok","timestamp":1603758331812,"user_tz":-420,"elapsed":1006,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class CBOWDataset(Dataset):\n","    def __init__(self, cbow_df, vectorizer):\n","        self.cbow_df = cbow_df\n","        self._vectorizer = vectorizer\n","\n","        # calculate how long the sequence could be\n","        measure_len = lambda context: len(context.split(\" \"))\n","        self._max_seq_length = max(map(measure_len, cbow_df.context))\n","        \n","        self.train_df = self.cbow_df[self.cbow_df.split == 'train']\n","        self.train_size = len(self.train_df)\n","        \n","        self.val_df = self.cbow_df[self.cbow_df.split == 'val']\n","        self.val_size = len(self.val_df)\n","        \n","        self.test_df = self.cbow_df[self.cbow_df.split == 'test']\n","        self.test_size = len(self.test_df)\n","        \n","        self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                            'val': (self.val_df, self.val_size),\n","                            'test': (self.test_df, self.test_size)}\n","        \n","        self.set_split('train')\n","        \n","    @classmethod\n","    def load_dataset_and_make_vectorizer(cls, cbow_csv, cuda=False):\n","        \"\"\"Load dataset from csv and returns the dataset object\n","        and vectorizer\"\"\"\n","        cbow_df = pd.read_csv(cbow_csv)\n","        train_cbow_df = cbow_df[cbow_df.split == 'train']\n","        return cls(cbow_df,\n","                   CBOWVectorizer.from_dataframe(train_cbow_df))\n","    \n","    def get_vectorizer(self):\n","        \"\"\"Get vectorizer\"\"\"\n","        return self._vectorizer\n","    \n","    def set_split(self, split='train'):\n","        \"\"\"Set the split from data\"\"\"\n","        self._target_split = split\n","        self._target_df, self._target_size = self._lookup_dict[split]\n","        \n","    def __len__(self):\n","        return self._target_size\n","    \n","    def __getitem__(self, index):\n","        \"\"\"the primary entry point method for PyTorch datasets\n","        Args:\n","            index (int): the index to the data point\n","        Returns:\n","            a dict of the data point's features (x_data) and label (y_target)\n","        \"\"\"\n","        row = self._target_df.iloc[index]\n","        \n","        context_vector = self._vectorizer.vectorize(row.context,\n","                                                    self._max_seq_length)\n","        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n","        \n","        return {\n","            'x_data' : context_vector,\n","            'y_target' : target_index\n","        }\n","    \n","    def get_num_batches(self, batch_size):\n","        \"\"\"Given the batch size return the number of batches in the dataset\"\"\"\n","        return len(self) // batch_size"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KhkBU_UZZo7N"},"source":["## CBOW Classifier"]},{"cell_type":"code","metadata":{"id":"iD0ExhjcZrLS","executionInfo":{"status":"ok","timestamp":1603758323010,"user_tz":-420,"elapsed":1267,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["class CBOWClassifier(nn.Module):\n","    def __init__(self, vocab_size, embedding_size, padding_idx=0, dropout=.1):\n","        super(CBOWClassifier, self).__init__()\n","\n","        self.embedding = nn.Embedding(num_embeddings= vocab_size,\n","                                      embedding_dim= embedding_size,\n","                                      padding_idx= padding_idx)\n","        self.fc1 = nn.Linear(in_features= embedding_size,\n","                             out_features= vocab_size)\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","    def forward(self, x_in, apply_softmax=False):\n","        x_embedding_sum = self.embedding(x_in).sum(dim=1)\n","        y_out = self.fc1(x_embedding_sum)\n","\n","        if self.training:\n","            y_out = self.dropout(y_out)\n","        if apply_softmax:\n","            y_out = torch.softmax(y_out, dim=1)\n","        \n","        return y_out"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRdsRwn8brxM"},"source":["## Training Routine"]},{"cell_type":"code","metadata":{"id":"lSBO1LfbbuL-","executionInfo":{"status":"ok","timestamp":1603760560068,"user_tz":-420,"elapsed":1173,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["args = Namespace(\n","    # Data information\n","    frequency_cutoff = 25,\n","    model_state_file = '/content/drive/My Drive/Colab Notebooks/Data/model.pth',\n","    cbow_csv = '/content/drive/My Drive/Colab Notebooks/Data/frankenstein_with_splits.csv',\n","    save_dir = '/content/drive/My Drive/Colab Notebooks/Data',\n","    vectorizer_file = '/content/drive/My Drive/Colab Notebooks/Data/vectorizer.json',\n","    # Model HyperParameters\n","    embedding_size=300,\n","    # Training HyperParameters\n","    batch_size = 128,\n","    early_stopping_criteria=5,\n","    learning_rate=0.001,\n","    momentum=0.1,\n","    num_epochs=100,\n","    seed=1337,\n","    cuda=True,\n","    dropout=0.1\n",")\n","\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"):\n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will\n","    ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last)\n","\n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        for name, tensor in data_dict.items():\n","            out_data_dict[name] = data_dict[name].to(device)\n","        yield out_data_dict"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"phqm_r8ScTSh","executionInfo":{"status":"ok","timestamp":1603760571885,"user_tz":-420,"elapsed":7347,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"67f72cf6-de8b-4796-eddb-c1669d1b4de1","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# create variables to record\n","# the training process\n","def make_train_state(args):\n","    return {\n","        'epoch_index':0,\n","        'train_loss':[],\n","        'train_acc':[],\n","        'val_loss': [],\n","        'val_acc': [],\n","        'test_loss': -1,\n","        'test_acc': -1,\n","    }\n","\n","def compute_accuracy(y_pred, y_target):\n","    _, y_pred_indices = y_pred.max(dim=1)\n","    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","    return n_correct / len(y_pred_indices) * 100\n","\n","train_state = make_train_state(args)\n","\n","if torch.cuda.is_available() and args.cuda:\n","  args.cuda = True\n","else:\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Device available \", args.device)\n","\n","# dataset object\n","dataset = CBOWDataset.load_dataset_and_make_vectorizer(args.cbow_csv)\n","\n","# vectorizer\n","vectorizer = dataset.get_vectorizer()\n","\n","# classifier\n","classifier = CBOWClassifier(vocab_size= len(vectorizer.cbow_vocab),\n","                            embedding_size= args.embedding_size,\n","                            dropout= args.dropout)\n","classifier = classifier.to(args.device)\n","\n","# loss function and optimizer\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","\n","print(\"Embedding dim \", args.embedding_size)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Device available  cuda\n","Embedding dim  300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G7m-HyisdO_k","executionInfo":{"status":"ok","timestamp":1603761932512,"user_tz":-420,"elapsed":1354547,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"99dbdbbb-f435-4da7-c2d9-d79aad84eaaa","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["dd6361e5683b4b61a360684e47e575d3","04d6dd657ea843dd9cdcd854479d3c9a","e178d5fcf23b460785143e9fa5bb9aaa","7929cbb3bb384b7dafbb1984641b3180","b7f665c3f18c42d48bb609db739e93df","1efbdf1a68cf462b80f8634f611ea093","03bf28eb68924ab49f1b097f9f0ccda9","2fda08123b0f4f4f9ad6dccd190f6c52","0a8e971e40a24a489d3ca2ec3e961c41","65e3b80fc66b4955851b8b0195154331","c1dd36a31f704c628e77a6cf0b8f4bee","bc91e6f8924041de97bdb26e878db527","d858579e54c74ea39348c21a2616f290","2f86921073cf4145b3a76b13fe9430ef","5899274073364ea7810f5a8fdc3325b7","8e512d420b31489f8ada44aba880dfee","aca67995d7fa4f8190ca42259b3aae05","42130394980a4d04aa32a22a87790f1f","ef36fd0e4ceb40c3963b3c0a9550a200","c71f54c2f1454767989117a790ca6438","d0310f6ac26245b790e5f579848ba469","30db7b30112d44a39e7cf92b83953f06","5035919f9f5f450e827fc851ecc7dab5","e7a893ff91f6452bbef0474349fd3699"]}},"source":["# Create training loop\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size)-1, \n","                          position=1, \n","                          leave=True)\n","\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size)-1, \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","    for epoch_index in range(args.num_epochs):\n","        train_state['epoch_index'] = epoch_index\n","        # setup batch generator\n","        # set loss and train mode on\n","        dataset.set_split('train')\n","        batch_generator = generate_batches(dataset=dataset,\n","                                        batch_size=args.batch_size,\n","                                        device=args.device)\n","      \n","        running_loss = 0.0\n","        running_acc = 0.0\n","        classifier.train()\n","      \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # step 1 zero the gradients\n","            optimizer.zero_grad()\n","          \n","            # step 2 compute the output\n","            y_pred = classifier(x_in=batch_dict['x_data'])\n","          \n","            # step 3 compute the loss\n","            loss = loss_func(y_pred, batch_dict['y_target'])\n","            loss_batch = loss.item()\n","            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","          \n","            # step 4 use loss to produce gradients\n","            loss.backward()\n","          \n","            # step 5 use optimizer to take the gradient step\n","            optimizer.step()\n","          \n","            # step 6 compute the acccuracy\n","            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","\n","            # update bar\n","            train_bar.set_postfix(loss=running_loss, \n","                                acc=running_acc, \n","                                epoch=epoch_index)\n","            train_bar.update()\n","          \n","        train_state['train_loss'].append(running_loss)\n","        train_state['train_acc'].append(running_acc)\n","      \n","        # Iterate over val dataset\n","        # setup: batch generator, set loss and acc to 0, set eval mode on\n","        dataset.set_split('val')\n","        batch_generator = generate_batches(dataset,\n","                                        batch_size=args.batch_size,\n","                                        device=args.device)\n","      \n","        running_loss = 0.\n","        running_acc = 0.\n","        classifier.eval()\n","      \n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            # step 1. compute the output\n","            y_pred = classifier(x_in=batch_dict['x_data'])\n","          \n","            # step 2. compute the loss\n","            loss = loss_func(y_pred, batch_dict['y_target'])\n","            loss_batch = loss.item()\n","            running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","          \n","            # step 3. compute the accuracy\n","            acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","            running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","            train_state['val_loss'].append(running_loss)\n","            train_state['val_acc'].append(running_acc)\n","            \n","            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                            epoch=epoch_index)\n","            val_bar.update()\n","          \n","        train_state['val_loss'].append(running_loss)\n","        train_state['val_acc'].append(running_acc)\n","\n","        train_bar.n = 0\n","        val_bar.n = 0\n","        epoch_bar.update()\n","except KeyboardInterrupt:\n","    print(\"Exiting loop\") "],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd6361e5683b4b61a360684e47e575d3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a8e971e40a24a489d3ca2ec3e961c41","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=495.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aca67995d7fa4f8190ca42259b3aae05","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=105.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"D94OKrMWkS6i","executionInfo":{"status":"ok","timestamp":1603762397784,"user_tz":-420,"elapsed":2902,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"ad357c92-25d3-45a0-932a-8e62a15ae441","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# evaluate the model\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset,\n","                                   args.batch_size,\n","                                   device=args.device)\n","\n","running_loss = 0.\n","running_acc = 0.\n","classifier.eval()\n","\n","for batch_index, batch_dict in enumerate(batch_generator):\n","  # compute the output\n","  y_pred = classifier(x_in=batch_dict['x_data'])\n","\n","  # compute the loss\n","  loss = loss_func(y_pred, batch_dict['y_target'])\n","  loss_batch = loss.item()\n","  running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","\n","  # compute the accuracy\n","  acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n","  running_acc += (acc_batch - running_acc) / (batch_index + 1)\n","\n","train_state['test_loss'] = running_loss\n","train_state['test_acc'] = running_acc\n","\n","print(\"Test loss : {:.3f}\".format(train_state['test_loss']))\n","print(\"Test acc : {:.3f}\".format(train_state['test_acc']))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Test loss : 19.377\n","Test acc : 10.245\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter5_word_embeddings.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"17zFV3T3mqCQqNvqn3qcJDpqY4UtXuzYk","authorship_tag":"ABX9TyNg+avBvWqm7HDlGXrGHT+G"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2Pnca6S29isj"},"source":["# Using PreTrained Word Embeddings"]},{"cell_type":"code","metadata":{"id":"IGVPwaIa-RuK","executionInfo":{"status":"ok","timestamp":1603700105940,"user_tz":-420,"elapsed":13804,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"7040147a-1de3-4a49-c0aa-7b16e3bb76ee","colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["# install annoy package\n","!pip install annoy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting annoy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/5b/1c22129f608b3f438713b91cd880dc681d747a860afe3e8e0af86e921942/annoy-1.17.0.tar.gz (646kB)\n","\r\u001b[K     |▌                               | 10kB 11.7MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 655kB 2.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: annoy\n","  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for annoy: filename=annoy-1.17.0-cp36-cp36m-linux_x86_64.whl size=390351 sha256=2ecd228e4089124a82b992bb6545c3ac6204233d7da30a6a3b31465f4f69ee91\n","  Stored in directory: /root/.cache/pip/wheels/3a/c5/59/cce7e67b52c8e987389e53f917b6bb2a9d904a03246fadcb1e\n","Successfully built annoy\n","Installing collected packages: annoy\n","Successfully installed annoy-1.17.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"np62kifp9UxL","executionInfo":{"status":"ok","timestamp":1603702799350,"user_tz":-420,"elapsed":1527,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["import numpy as np\n","from annoy import AnnoyIndex\n","\n","class PreTrainedEmbeddings(object):\n","    def __init__(self, word_to_index, word_vectors):\n","        self.word_to_index = word_to_index\n","        self.word_vectors = word_vectors\n","\n","        self.index_to_word = {\n","            idx: word for word, idx in self.word_to_index.items()\n","        }\n","\n","        self.index = AnnoyIndex(len(self.word_vectors[0]),\n","                                metric='euclidean')\n","        \n","        for _, i in self.word_to_index.items():\n","            self.index.add_item(i, self.word_vectors[i])\n","        self.index.build(50)\n","\n","    @classmethod\n","    def from_embeddings_file(cls, embedding_file):\n","        word_to_index = {}\n","        word_vectors = []\n","\n","        with open(embedding_file) as f:\n","            for line in f.readlines():\n","                line = line.split(\" \")\n","                word = line[0]\n","                vec = np.array([float(val) for val in line[1:]])\n","\n","                word_to_index[word] = len(word_to_index)\n","                word_vectors.append(vec)\n","        return cls(word_to_index, word_vectors)\n","\n","    def get_embedding(self, word):\n","        \"\"\"\n","        Get embedding values given a word\n","        Args:\n","            word(str): word to find\n","        Returns:\n","            embedding vector (np.ndarray)\n","        \"\"\"\n","        return self.word_vectors[self.word_to_index[word]]\n","\n","    def get_closest_vector(self, vector, neighbors=1):\n","        \"\"\"\n","        Get neighboring words given a vector\n","        Args:\n","            vector (np.ndarray): embedding vector\n","            neighbors (int): number of neighbors to return\n","        Returns:\n","            List of neighboring words list(str)\n","        \"\"\"\n","        neighbors_indices = self.index.get_nns_by_vector(vector,\n","                                                        neighbors)\n","        return [self.index_to_word[idx] for idx in neighbors_indices]\n","\n","    def compute_analogy(self, word1, word2, word3):\n","        \"\"\"\n","        Get Analogy of given words\n","        Args:\n","            word1 - word3 (str): words to find\n","        Returns:\n","            Shows the analogy of given words\n","        \"\"\"\n","        vector1 = self.get_embedding(word1)\n","        vector2 = self.get_embedding(word2)\n","        vector3 = self.get_embedding(word3)\n","\n","        # compute the spatial relationship\n","        # from vector1 and vector2\n","        # the relationsihp of vector3 is\n","        # vector3 + spatial_relationship\n","        spatial_relationship = vector2 - vector1\n","        vector4 = vector3 + spatial_relationship\n","\n","        # from vector get it's relationship (neighbors)\n","        neighbors = self.get_closest_vector(vector4, 4)\n","        existing_words = set([word1, word2, word3])\n","        neighbors = set(neighbors)\n","        closest_words = [word for word in neighbors\n","                         if word not in existing_words]\n","\n","        if len(closest_words) == 0:\n","            print(\"No closest words found\")\n","            return\n","        \n","        for word4 in closest_words:\n","            print(\"{} : {} :: {} : {}\".format(word1,\n","                                              word2,\n","                                              word3,\n","                                              word4))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqU-BXQEBmWf","executionInfo":{"status":"ok","timestamp":1603702843335,"user_tz":-420,"elapsed":41752,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}}},"source":["# load the embedding file\n","embedding_file = \"/content/drive/My Drive/Colab Notebooks/Data/Glove/glove.6B.100d.txt\"\n","embeddings = PreTrainedEmbeddings.from_embeddings_file(embedding_file)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkhTW-TEGxCv","executionInfo":{"status":"ok","timestamp":1603702986541,"user_tz":-420,"elapsed":1660,"user":{"displayName":"MIQDAD ABDURRAHMAN (00000012596)","photoUrl":"","userId":"02624905681309133053"}},"outputId":"5603bc8b-643f-46a4-a81c-f3a95cd32cc4","colab":{"base_uri":"https://localhost:8080/","height":303}},"source":["embeddings.compute_analogy('man', 'he', 'woman')\n","embeddings.compute_analogy('fly', 'plane', 'sail')\n","embeddings.compute_analogy('blue', 'color', 'dog')\n","embeddings.compute_analogy('fast', 'fastest', 'small')\n","# gender bias\n","embeddings.compute_analogy('man', 'doctor', 'woman')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["man : he :: woman : she\n","man : he :: woman : her\n","fly : plane :: sail : ship\n","fly : plane :: sail : vessel\n","fly : plane :: sail : boat\n","blue : color :: dog : touch\n","blue : color :: dog : animal\n","blue : color :: dog : taste\n","blue : color :: dog : pet\n","fast : fastest :: small : quarters\n","fast : fastest :: small : among\n","fast : fastest :: small : smallest\n","fast : fastest :: small : largest\n","man : doctor :: woman : physician\n","man : doctor :: woman : doctors\n","man : doctor :: woman : nurse\n"],"name":"stdout"}]}]}